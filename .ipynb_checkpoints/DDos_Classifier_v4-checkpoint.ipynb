{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urkkDPRZ3kiK"
   },
   "source": [
    "# Load and Train the desire testing dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "A0pM_2lme9-u",
    "outputId": "64600cd2-10dc-4b45-8f71-896fbde8d906"
   },
   "outputs": [],
   "source": [
    "#from google.colab import drive\n",
    "#drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Be-80uIesm83",
    "outputId": "efb70b8e-0adc-4e98-bb4c-75443c2ceb2c",
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmodel_selection\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m train_test_split\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/__init__.py:138\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    121\u001b[0m     concat,\n\u001b[1;32m    122\u001b[0m     lreshape,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     qcut,\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing  \u001b[38;5;66;03m# noqa:PDF015\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_print_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     ExcelFile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     read_spss,\n\u001b[1;32m    172\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/testing.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mPublic testing utility functions.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_testing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     assert_extension_array_equal,\n\u001b[1;32m      8\u001b[0m     assert_frame_equal,\n\u001b[1;32m      9\u001b[0m     assert_index_equal,\n\u001b[1;32m     10\u001b[0m     assert_series_equal,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_extension_array_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_frame_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_series_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_index_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/_testing/__init__.py:903\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytest\u001b[39;00m\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pytest\u001b[38;5;241m.\u001b[39mraises(expected_exception, match\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# noqa: PDF010\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m cython_table \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241m.\u001b[39mcommon\u001b[38;5;241m.\u001b[39m_cython_table\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[1;32m    907\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;124;03m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    keys and expected result.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;03m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# data = pd.read_csv('https://ddosciu.s3.us-east-2.amazonaws.com/CSVs/UNB/Portmap.csv')\n",
    "# data = pd.read_csv('https://unsw-my.sharepoint.com/:x:/r/personal/z5025758_ad_unsw_edu_au/_layouts/15/Doc.aspx?sourcedoc=%7B2A810F6A-CC3D-4D98-909E-37489D8DAF98%7D&file=UNSW_NB15_testing-set.csv&action=default&mobileredirect=true')\n",
    "data = pd.read_csv(\"https://ddosciu.s3.us-east-2.amazonaws.com/Portmap.csv\")\n",
    "data_2 = pd.read_csv(\"https://ddosciu.s3.us-east-2.amazonaws.com/UNSW-NB15_4.csv\")\n",
    "data_3 = pd.read_csv(\"https://ddosciu.s3.us-east-2.amazonaws.com/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvmFf5QQMATU"
   },
   "source": [
    "# Pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMPU8utHMMvF"
   },
   "source": [
    "## Dataset1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "9Q4GgIqjLt1N",
    "outputId": "aed421e2-28f8-4c09-b868-5536dafb26ef"
   },
   "outputs": [],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1zvZB0tfSSyF"
   },
   "outputs": [],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Am30-F0PhEXd"
   },
   "outputs": [],
   "source": [
    "# data = data[[' Source IP', ' Source Port',' Destination IP', ' Destination Port', ' Protocol',\n",
    "#        ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
    "#        'Total Length of Fwd Packets', ' Total Length of Bwd Packets',' Label']]\n",
    "\n",
    "data = data[[' Source IP', ' Source Port',' Destination IP', ' Destination Port',\n",
    "       ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
    "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',' Label']]\n",
    "\n",
    "# Map labels in data_1 to binary\n",
    "data[' Label'] = data[' Label'].map({\n",
    "    'BENIGN': 0,\n",
    "    'NetBIOS': 1,\n",
    "    'LDAP': 1\n",
    "})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ETVxFV9obG4U"
   },
   "outputs": [],
   "source": [
    "data[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "MdJaHrHMb3Xz"
   },
   "outputs": [],
   "source": [
    "# # Set the desired number of majority class samples\n",
    "# num_majority_samples = 20000 #100000\n",
    "#\n",
    "# # Get the minority class label\n",
    "# minority_class = data[' Label'].value_counts().idxmin()\n",
    "\n",
    "# # Separate majority and minority class samples\n",
    "# majority_samples = data[data[' Label'] != minority_class]\n",
    "# minority_samples = data[data[' Label'] == minority_class]\n",
    "\n",
    "# # Sample the majority class samples\n",
    "# majority_samples_sampled = majority_samples.sample(num_majority_samples, random_state=42)\n",
    "\n",
    "# # Combine the sampled majority class samples and minority class samples\n",
    "# balanced_data = pd.concat([majority_samples_sampled, minority_samples], axis=0)\n",
    "\n",
    "# # Shuffle the balanced dataset\n",
    "# balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# balanced_data.head()\n",
    "# num_unique_labels = balanced_data[' Label'].nunique()\n",
    "# print(\"Number of unique labels in the balanced data:\", num_unique_labels)\n",
    "# label_frequency = balanced_data[' Label'].value_counts()\n",
    "# print(\"Frequency of each unique label in the balanced data:\")\n",
    "# print(label_frequency)\n",
    "# label_frequency_data = data[' Label'].value_counts()\n",
    "# print(\"Frequency of each unique label in the original data:\")\n",
    "# print(label_frequency_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ciHA5fClpP6_"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Set the desired number of majority class samples\n",
    "num_majority_samples = 15000  # Adjust this number as needed\n",
    "\n",
    "# Get the minority class label\n",
    "minority_class = data[' Label'].value_counts().idxmin()\n",
    "\n",
    "# Separate majority and minority class samples\n",
    "majority_samples = data[data[' Label'] != minority_class]\n",
    "minority_samples = data[data[' Label'] == minority_class]\n",
    "\n",
    "# Sample the majority class samples\n",
    "majority_samples_sampled = majority_samples.sample(num_majority_samples, random_state=42)\n",
    "\n",
    "# Upsample the minority class samples\n",
    "minority_samples_upsampled = resample(\n",
    "    minority_samples,\n",
    "    replace=True,  # Sample with replacement\n",
    "    n_samples=num_majority_samples,  # Match the number of majority samples\n",
    "    random_state=42  # Reproducible results\n",
    ")\n",
    "\n",
    "# Combine the sampled majority class samples and upsampled minority class samples\n",
    "balanced_data = pd.concat([majority_samples_sampled, minority_samples_upsampled], axis=0)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print some information about the balanced dataset\n",
    "balanced_data.head()\n",
    "num_unique_labels = balanced_data[' Label'].nunique()\n",
    "print(\"Number of unique labels in the balanced data:\", num_unique_labels)\n",
    "label_frequency = balanced_data[' Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the balanced data:\")\n",
    "print(label_frequency)\n",
    "label_frequency_data = data[' Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the original data:\")\n",
    "print(label_frequency_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NzNu3IMeaYH-"
   },
   "outputs": [],
   "source": [
    "data=balanced_data.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ceXZAikX_YZa"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3n-wgNGMWH3"
   },
   "source": [
    "## Dataset2 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UeX0y2rTACvI"
   },
   "outputs": [],
   "source": [
    "data_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Cd0L_ETF4p_B"
   },
   "outputs": [],
   "source": [
    "data_2[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mMKKWtauAN-z"
   },
   "outputs": [],
   "source": [
    "data_2['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oaEigChD5lZ4"
   },
   "outputs": [],
   "source": [
    "# Print unique values in 'attack_cat' column\n",
    "print(set(data_2['attack_cat']))\n",
    "\n",
    "# Replace NaN values with 'Normal'\n",
    "data_2['attack_cat'].fillna('Normal', inplace=True)\n",
    "\n",
    "# Filter data_2 to keep only 'DoS' and 'Normal' rows\n",
    "data_2 = data_2[data_2['attack_cat'].isin(['DoS', 'Normal'])]\n",
    "\n",
    "# # Map 'DoS' to 1 (attack) and 'Normal' to 0 (benign) in data_2\n",
    "# data_2['label'] = data_2['attack_cat'].map({\n",
    "#     'Normal': 0,\n",
    "#     'DoS': 1\n",
    "# })\n",
    "\n",
    "# Verify the filtering\n",
    "print(data_2['attack_cat'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "QZsrc5U2Akom"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Fh-rP7cxCz33"
   },
   "outputs": [],
   "source": [
    "# data_2= data_2[['srcip', 'sport', 'dstip', 'dsport', 'proto','dur',  'Spkts', 'Dpkts', 'sbytes',\n",
    "#        'dbytes', 'Label']]\n",
    "# protocol_mapping = {\n",
    "#     '3pc': 34, 'a/n': 155, 'aes-sp3-d': 108, 'any': 127, 'argus': 13, 'aris': 104, 'arp': 0, 'ax.25': 93, 'bbn-rcc': 10,\n",
    "#     'bna': 49, 'br-sat-mon': 76, 'cbt': 7, 'cftp': 62, 'chaos': 16, 'compaq-peer': 110, 'cphb': 73, 'cpnx': 72, 'crtp': 84,\n",
    "#     'crudp': 86, 'dcn': 0, 'ddp': 37, 'ddx': 116, 'dgp': 86, 'egp': 8, 'eigrp': 88, 'emcon': 14, 'encap': 98, 'etherip': 97,\n",
    "#     'fc': 133, 'fire': 125, 'ggp': 3, 'gmtp': 100, 'gre': 47, 'hmp': 20, 'i-nlsp': 52, 'iatp': 117, 'ib': 243, 'icmp': 1,\n",
    "#     'idpr': 35, 'idpr-cmtp': 38, 'idrp': 45, 'ifmp': 101, 'igmp': 2, 'igp': 9, 'il': 40, 'ip': 0, 'ipcomp': 108, 'ipcv': 71,\n",
    "#     'ipip': 4, 'iplt': 129, 'ipnip': 68, 'ippc': 67, 'ipv6': 41, 'ipv6-frag': 44, 'ipv6-no': 59, 'ipv6-opts': 60, 'ipv6-route': 43,\n",
    "#     'ipx-n-ip': 111, 'irtp': 28, 'isis': 124, 'iso-ip': 80, 'iso-tp4': 29, 'kryptolan': 65, 'l2tp': 115, 'larp': 91, 'leaf-1': 25,\n",
    "#     'leaf-2': 26, 'merit-inp': 32, 'mfe-nsp': 31, 'mhrp': 48, 'micp': 95, 'mobile': 55, 'mtp': 92, 'mux': 18, 'narp': 54, 'netblt': 30,\n",
    "#     'nsfnet-igp': 85, 'nvp': 11, 'ospf': 89, 'pgm': 113, 'pim': 103, 'pipe': 109, 'pnni': 102, 'pri-enc': 44, 'prm': 129, 'ptp': 123,\n",
    "#     'pup': 12, 'pvp': 75, 'qnx': 106, 'rdp': 27, 'rsvp': 46, 'rtp': 50, 'rvd': 66, 'sat-expak': 64, 'sat-mon': 69, 'sccopmce': 0,\n",
    "#     'scps': 53, 'sctp': 132, 'sdrp': 42, 'secure-vmtp': 82, 'sep': 33, 'skip': 57, 'sm': 122, 'smp': 121, 'snp': 109, 'sprite-rpc': 90,\n",
    "#     'sps': 129, 'srp': 126, 'st2': 5, 'stp': 118, 'sun-nd': 77, 'swipe': 53, 'tcf': 87, 'tcp': 6, 'tlsp': 56, 'tp++': 39, 'trunk-1': 23,\n",
    "#     'trunk-2': 24, 'ttp': 84, 'udp': 17, 'unas': 63, 'uti': 10, 'vines': 83, 'visa': 70, 'vmtp': 81, 'vrrp': 112, 'wb-expak': 79,\n",
    "#     'wb-mon': 78, 'wsn': 112, 'xnet': 15, 'xns-idp': 22, 'xtp': 36, 'zero': 255\n",
    "# }\n",
    "\n",
    "# # Apply the mapping\n",
    "# data_2['proto'] = data_2['proto'].map(protocol_mapping)\n",
    "\n",
    "# data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "NaFrbWLxfbm-"
   },
   "outputs": [],
   "source": [
    "data_2= data_2[['srcip', 'sport', 'dstip', 'dsport','dur',  'Spkts', 'Dpkts', 'sbytes',\n",
    "       'dbytes', 'Label']]\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gcYCffhU32nC"
   },
   "outputs": [],
   "source": [
    "data_2['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ubkGgDbgO_j5"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Set the desired number of majority class samples\n",
    "num_majority_samples = 15000  # Adjust this number as needed\n",
    "\n",
    "# Get the minority class label\n",
    "minority_class = data_2['Label'].value_counts().idxmin()\n",
    "\n",
    "# Separate majority and minority class samples\n",
    "majority_samples = data_2[data_2['Label'] != minority_class]\n",
    "minority_samples = data_2[data_2['Label'] == minority_class]\n",
    "\n",
    "# Sample the majority class samples\n",
    "majority_samples_sampled = majority_samples.sample(num_majority_samples, random_state=42)\n",
    "\n",
    "# Upsample the minority class samples\n",
    "minority_samples_upsampled = resample(\n",
    "    minority_samples,\n",
    "    replace=True,  # Sample with replacement\n",
    "    n_samples=num_majority_samples,  # Match the number of majority samples\n",
    "    random_state=42  # Reproducible results\n",
    ")\n",
    "\n",
    "# Combine the sampled majority class samples and upsampled minority class samples\n",
    "balanced_data_2 = pd.concat([majority_samples_sampled, minority_samples_upsampled], axis=0)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_data_2 = balanced_data_2.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print some information about the balanced dataset\n",
    "balanced_data.head()\n",
    "num_unique_labels = balanced_data_2['Label'].nunique()\n",
    "print(\"Number of unique labels in the balanced data:\", num_unique_labels)\n",
    "label_frequency = balanced_data_2['Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the balanced data:\")\n",
    "print(label_frequency)\n",
    "label_frequency_data = data_2['Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the original data:\")\n",
    "print(label_frequency_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "OY28Y2JfO__L"
   },
   "outputs": [],
   "source": [
    "data_2 =  balanced_data_2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOuY2pwhMc6G"
   },
   "source": [
    "## Dataset3 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mhVnzDNiMgO3"
   },
   "outputs": [],
   "source": [
    "data_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ny_qGk3iP2nF"
   },
   "outputs": [],
   "source": [
    "# data_3 = data_3[[' Source IP', ' Source Port', ' Destination IP',\n",
    "#        ' Destination Port', ' Protocol', ' Flow Duration',\n",
    "#        ' Total Fwd Packets', ' Total Backward Packets',\n",
    "      #  'Total Length of Fwd Packets', ' Total Length of Bwd Packets',' Label']]\n",
    "data_3 = data_3[[' Source IP', ' Source Port', ' Destination IP',\n",
    "       ' Destination Port',' Flow Duration',\n",
    "       ' Total Fwd Packets', ' Total Backward Packets',\n",
    "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',' Label']]\n",
    "\n",
    "data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gt5Y5TPAQuKg"
   },
   "outputs": [],
   "source": [
    "print(set(data_3[' Label']))\n",
    "\n",
    "data_3[' Label'].value_counts()\n",
    "# Map labels in data_1 to binary\n",
    "data_3[' Label'] = data_3[' Label'].map({\n",
    "    'BENIGN': 0,\n",
    "    'DDoS': 1})\n",
    "\n",
    "data_3[' Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xgu8cObb51PX"
   },
   "outputs": [],
   "source": [
    "data_3[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "AdcxcB6yifiO"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Set the desired number of majority class samples\n",
    "num_majority_samples = 15000  # Adjust this number as needed\n",
    "\n",
    "# Get the minority class label\n",
    "minority_class = data_3[' Label'].value_counts().idxmin()\n",
    "\n",
    "# Separate majority and minority class samples\n",
    "majority_samples = data_3[data_3[' Label'] != minority_class]\n",
    "minority_samples = data_3[data_3[' Label'] == minority_class]\n",
    "\n",
    "# Sample the majority class samples\n",
    "majority_samples_sampled = majority_samples.sample(num_majority_samples, random_state=42)\n",
    "\n",
    "# Upsample the minority class samples\n",
    "minority_samples_upsampled = resample(\n",
    "    minority_samples,\n",
    "    replace=True,  # Sample with replacement\n",
    "    n_samples=num_majority_samples,  # Match the number of majority samples\n",
    "    random_state=42  # Reproducible results\n",
    ")\n",
    "\n",
    "# Combine the sampled majority class samples and upsampled minority class samples\n",
    "balanced_data_3 = pd.concat([majority_samples_sampled, minority_samples_upsampled], axis=0)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_data_3 = balanced_data_3.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print some information about the balanced dataset\n",
    "balanced_data.head()\n",
    "num_unique_labels = balanced_data_3[' Label'].nunique()\n",
    "print(\"Number of unique labels in the balanced data:\", num_unique_labels)\n",
    "label_frequency = balanced_data_3[' Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the balanced data:\")\n",
    "print(label_frequency)\n",
    "label_frequency_data = data_3[' Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the original data:\")\n",
    "print(label_frequency_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s4TpOjXpj5xd"
   },
   "outputs": [],
   "source": [
    "data_3 = balanced_data_3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNnplKV5MmZi"
   },
   "source": [
    "## Standardizing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cxDhrs85RIch"
   },
   "outputs": [],
   "source": [
    "data.columns,data_2.columns,data_3.columns,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "wIyTViFfTWtZ"
   },
   "outputs": [],
   "source": [
    "# Standardize column names\n",
    "rename_dict = {\n",
    "    ' Source IP': 'src_ip', ' Source Port': 'src_port', ' Destination IP': 'dst_ip', ' Destination Port': 'dst_port',\n",
    "    ' Protocol': 'protocol', ' Flow Duration': 'flow_duration', ' Total Fwd Packets': 'total_fwd_packets',\n",
    "    ' Total Backward Packets': 'total_bwd_packets', 'Total Length of Fwd Packets': 'total_len_fwd_packets',\n",
    "    ' Total Length of Bwd Packets': 'total_len_bwd_packets', ' Label': 'label',\n",
    "\n",
    "    'srcip': 'src_ip', 'sport': 'src_port', 'dstip': 'dst_ip', 'dsport': 'dst_port',\n",
    "    'proto': 'protocol', 'dur': 'flow_duration', 'Spkts': 'total_fwd_packets', 'Dpkts': 'total_bwd_packets',\n",
    "    'sbytes': 'total_len_fwd_packets', 'dbytes': 'total_len_bwd_packets', 'Label': 'label'\n",
    "}\n",
    "\n",
    "data.rename(columns=rename_dict, inplace=True)\n",
    "data_2.rename(columns=rename_dict, inplace=True)\n",
    "data_3.rename(columns=rename_dict, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cA_6Oi0HTfiR"
   },
   "outputs": [],
   "source": [
    "data.columns,data_2.columns,data_3.columns,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "je4r0x97SWz8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_MGSeFEM38Z"
   },
   "source": [
    "## Preparing Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7iiMZNqDiAZ6"
   },
   "outputs": [],
   "source": [
    "# # Encode categorical features (e.g., IP addresses)\n",
    "# encoder = LabelEncoder()\n",
    "# data['src_ip'] = encoder.fit_transform(data['src_ip'])\n",
    "# data['dst_ip'] = encoder.fit_transform(data['dst_ip'])\n",
    "# # data['protocol'] = encoder.fit_transform(data['protocol'])\n",
    "# data['label'] = encoder.fit_transform(data['label'])\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "41ONtYl-Xrmi"
   },
   "outputs": [],
   "source": [
    "# # Encode categorical features (e.g., IP addresses)\n",
    "# encoder1 = LabelEncoder()\n",
    "# data_2['src_ip'] = encoder1.fit_transform(data_2['src_ip'])\n",
    "# data_2['dst_ip'] = encoder1.fit_transform(data_2['dst_ip'])\n",
    "# # data['protocol'] = encoder.fit_transform(data_2['protocol'])\n",
    "# data_2['label'] = encoder1.fit_transform(data_2['label'])\n",
    "# data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "04Wcuy1jX6bH"
   },
   "outputs": [],
   "source": [
    "# # Encode categorical features (e.g., IP addresses)\n",
    "# encoder3 = LabelEncoder()\n",
    "# data_3['src_ip'] = encoder3.fit_transform(data_3['src_ip'])\n",
    "# data_3['dst_ip'] = encoder3.fit_transform(data_3['dst_ip'])\n",
    "# # data_3['protocol'] = encoder.fit_transform(data_3['protocol'])\n",
    "# data_3['label'] = encoder3.fit_transform(data_3['label'])\n",
    "# data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ErMV4UYTYvGj"
   },
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# Handle missing values\n",
    "data.fillna(0, inplace=True)\n",
    "data_2.fillna(0, inplace=True)\n",
    "data_3.fillna(0, inplace=True)\n",
    "\n",
    "# Combine the datasets vertically\n",
    "combined_data = pd.concat([data,data_2, data_3], ignore_index=True)\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "bUo4LpLQZDjk"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'combined_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mcombined_data\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlabel\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n",
      "\u001b[0;31mNameError\u001b[0m: name 'combined_data' is not defined"
     ]
    }
   ],
   "source": [
    "combined_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "A9fPtaTYX_Iq"
   },
   "outputs": [],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "aBTOHf3GVvlE"
   },
   "outputs": [],
   "source": [
    "# # Encode categorical features (e.g., IP addresses)\n",
    "# encoder = LabelEncoder()\n",
    "# combined_data['src_ip'] = encoder.fit_transform(combined_data['src_ip'])\n",
    "# combined_data['dst_ip'] = encoder.fit_transform(combined_data['dst_ip'])\n",
    "# # combined_data['protocol'] = encoder.fit_transform(combined_data['protocol'])\n",
    "# combined_data['label'] = encoder.fit_transform(combined_data['label'])\n",
    "# combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "_SMk4Y1kjcge"
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpreprocessing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m LabelEncoder\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpickle\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/__init__.py:138\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcore\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mreshape\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    121\u001b[0m     concat,\n\u001b[1;32m    122\u001b[0m     lreshape,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    134\u001b[0m     qcut,\n\u001b[1;32m    135\u001b[0m )\n\u001b[1;32m    137\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m api, arrays, errors, io, plotting, tseries\n\u001b[0;32m--> 138\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m testing  \u001b[38;5;66;03m# noqa:PDF015\u001b[39;00m\n\u001b[1;32m    139\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutil\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_print_versions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m show_versions\n\u001b[1;32m    141\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mio\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mapi\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m    142\u001b[0m     \u001b[38;5;66;03m# excel\u001b[39;00m\n\u001b[1;32m    143\u001b[0m     ExcelFile,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    171\u001b[0m     read_spss,\n\u001b[1;32m    172\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/testing.py:6\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;124;03mPublic testing utility functions.\u001b[39;00m\n\u001b[1;32m      3\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m----> 6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_testing\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      7\u001b[0m     assert_extension_array_equal,\n\u001b[1;32m      8\u001b[0m     assert_frame_equal,\n\u001b[1;32m      9\u001b[0m     assert_index_equal,\n\u001b[1;32m     10\u001b[0m     assert_series_equal,\n\u001b[1;32m     11\u001b[0m )\n\u001b[1;32m     13\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     14\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_extension_array_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     15\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_frame_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     16\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_series_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     17\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124massert_index_equal\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m     18\u001b[0m ]\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/pandas/_testing/__init__.py:903\u001b[0m\n\u001b[1;32m    898\u001b[0m     \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpytest\u001b[39;00m\n\u001b[1;32m    900\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m pytest\u001b[38;5;241m.\u001b[39mraises(expected_exception, match\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m)  \u001b[38;5;66;03m# noqa: PDF010\u001b[39;00m\n\u001b[0;32m--> 903\u001b[0m cython_table \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcore\u001b[49m\u001b[38;5;241m.\u001b[39mcommon\u001b[38;5;241m.\u001b[39m_cython_table\u001b[38;5;241m.\u001b[39mitems()\n\u001b[1;32m    906\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_cython_table_params\u001b[39m(ndframe, func_names_and_expected):\n\u001b[1;32m    907\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    908\u001b[0m \u001b[38;5;124;03m    Combine frame, functions from com._cython_table\u001b[39;00m\n\u001b[1;32m    909\u001b[0m \u001b[38;5;124;03m    keys and expected result.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    921\u001b[0m \u001b[38;5;124;03m        List of three items (DataFrame, function, expected result)\u001b[39;00m\n\u001b[1;32m    922\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "\u001b[0;31mAttributeError\u001b[0m: partially initialized module 'pandas' has no attribute 'core' (most likely due to a circular import)"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Create separate LabelEncoders for each categorical feature\n",
    "encoder_src_ip = LabelEncoder()\n",
    "encoder_dst_ip = LabelEncoder()\n",
    "encoder_src_port = LabelEncoder()\n",
    "encoder_dst_port = LabelEncoder()\n",
    "\n",
    "encoder_label = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical features\n",
    "combined_data['src_ip'] = encoder_src_ip.fit_transform(combined_data['src_ip'])\n",
    "combined_data['dst_ip'] = encoder_dst_ip.fit_transform(combined_data['dst_ip'])\n",
    "combined_data['src_port'] = encoder_src_port.fit_transform(combined_data['src_port'])\n",
    "combined_data['dst_port'] = encoder_dst_port.fit_transform(combined_data['dst_port'].astype(str))\n",
    "\n",
    "combined_data['label'] = encoder_label.fit_transform(combined_data['label'])\n",
    "\n",
    "# Save the encoders\n",
    "with open('encoder_src_ip.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder_src_ip, f)\n",
    "\n",
    "with open('encoder_dst_ip.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder_dst_ip, f)\n",
    "# Save the encoders\n",
    "with open('encoder_src_port.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder_src_port, f)\n",
    "\n",
    "with open('encoder_dst_port.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder_dst_port, f)\n",
    "\n",
    "with open('encoder_label.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder_label, f)\n",
    "\n",
    "print(\"Encoders saved successfully!\")\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "02peIEYc7HW-"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "s26T5AoCs-FD"
   },
   "outputs": [],
   "source": [
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DKXfXqVKm83F"
   },
   "outputs": [],
   "source": [
    "combined_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hly-X2lxty9k"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "X = combined_data.drop('label', axis=1)\n",
    "y = combined_data['label']\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify = y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "khLWdYqZ78lu"
   },
   "outputs": [],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "X9Ssmjv1t5_E"
   },
   "outputs": [],
   "source": [
    "X_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "7DarY50-t9TA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to check for data issues\n",
    "def check_data_issues(data):\n",
    "    if data.isnull().values.any():\n",
    "        print(\"There are NaN values in the dataset.\")\n",
    "    else:\n",
    "        print(\"No NaN values found in the dataset.\")\n",
    "\n",
    "    if np.isinf(data).values.any():\n",
    "        print(\"There are infinite values in the dataset.\")\n",
    "    else:\n",
    "        print(\"No infinite values found in the dataset.\")\n",
    "\n",
    "    max_value = data.max().max()\n",
    "    if max_value > np.finfo(np.float64).max:\n",
    "        print(f\"There are values too large for dtype('float64') in the dataset. Max value: {max_value}\")\n",
    "    else:\n",
    "        print(\"No values too large for dtype('float64') found in the dataset.\")\n",
    "\n",
    "    min_value = data.min().min()\n",
    "    if min_value < np.finfo(np.float64).min:\n",
    "        print(f\"There are values too small for dtype('float64') in the dataset. Min value: {min_value}\")\n",
    "    else:\n",
    "        print(\"No values too small for dtype('float64') found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "siqmSmeV615R"
   },
   "outputs": [],
   "source": [
    "# Separate numeric and categorical columns\n",
    "numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_columns = X_train.select_dtypes(exclude=[np.number]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "WvnfqNTI63x0"
   },
   "outputs": [],
   "source": [
    "# Separate numeric and categorical columns\n",
    "numeric_columns,categorical_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VXKEKw8guSJj"
   },
   "outputs": [],
   "source": [
    "# Replace infinity values with NaN\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Impute NaN values with the mean of the corresponding column\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Now, standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "PfnrV4BCt9nH"
   },
   "outputs": [],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "\n",
    "# Check the training and testing datasets for issues\n",
    "print(\"Checking X_train:\")\n",
    "check_data_issues(X_train)\n",
    "print(\"\\nChecking X_test:\")\n",
    "check_data_issues(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "rW2E-Hyy6RhG"
   },
   "outputs": [],
   "source": [
    "X_train.columns\n",
    "column_names =X_train.columns\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BXJO_fNc41Lv"
   },
   "outputs": [],
   "source": [
    "# type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zlpIcXMOvUX6"
   },
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTWVrQXmgA2r"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump\n",
    "\n",
    "# Create an empty DataFrame with the desired columns\n",
    "model_comparison = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"F1 Score\"])\n",
    "saved_models = {}  # Dictionary to store saved models\n",
    "\n",
    "\n",
    "# Train and evaluate machine learning models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC()\n",
    "}\n",
    "print(\"X shape\",X_train.shape)\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Append the metrics to the DataFrame\n",
    "    model_comparison = model_comparison._append({\"Model\": name, \"Accuracy\": accuracy, \"F1 Score\": f1}, ignore_index=True)\n",
    "\n",
    "    # Save the trained model weight\n",
    "    filename = f\"{name}_model.joblib\"\n",
    "    dump(model, filename)\n",
    "    saved_models[name] = filename  # Store the filename for later use in the tested DataSets\n",
    "\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 score: {f1}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Model saved as: {filename}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "display(model_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZt2ZB1ruj09"
   },
   "outputs": [],
   "source": [
    "# # Get the Random Forest model from the 'models' dictionary\n",
    "# random_forest_model = models['Random Forest']\n",
    "\n",
    "# # Get feature importances\n",
    "# importances = random_forest_model.feature_importances_\n",
    "\n",
    "# # Create a DataFrame with the feature names and their corresponding importances\n",
    "# feature_importances = pd.DataFrame({'Feature': feature_columns, 'Importance': importances})\n",
    "\n",
    "# # Sort the DataFrame by importance in descending order\n",
    "# feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# # Display the feature importances DataFrame\n",
    "# # Filter the DataFrame to show only features with non-zero importance\n",
    "# non_zero_importances = feature_importances[feature_importances['Importance'] > 0]\n",
    "\n",
    "# # Display the filtered DataFrame\n",
    "# non_zero_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hc_jAHTfuqMV"
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# # Choose the model you want to use, for example, Random Forest\n",
    "# model = models[\"Random Forest\"]\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# # Calculate the confusion matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# # Plot the confusion matrix using seaborn's heatmap\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=[\"0\", \"1\"], yticklabels=[\"0\", \"1\"])\n",
    "# plt.ylabel(\"True label\")\n",
    "# plt.xlabel(\"Predicted label\")\n",
    "# plt.title(\"Confusion Matrix - Random Forest\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wtvq0IxFsRSJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the DataFrame to store model comparison\n",
    "model_comparison = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"F1 Score\"])\n",
    "\n",
    "# Initialize dictionary to store confusion matrices\n",
    "confusion_matrices = {}\n",
    "\n",
    "# Initialize lists to store accuracy and F1 score for each model\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices[name] = cm\n",
    "\n",
    "    # Append results to model comparison DataFrame\n",
    "    model_comparison = model_comparison._append({\"Model\": name, \"Accuracy\": accuracy, \"F1 Score\": f1}, ignore_index=True)\n",
    "\n",
    "    # Append accuracy and F1 score to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print model evaluation metrics and confusion matrix\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 score: {f1}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Plotting accuracy scores\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(model_comparison['Model'], accuracy_scores, color='skyblue')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting F1 scores\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(model_comparison['Model'], f1_scores, color='orange')\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Displaying the model comparison DataFrame\n",
    "print(\"Model Comparison:\")\n",
    "print(model_comparison)\n",
    "\n",
    "# Plot confusion matrices for each model using Seaborn\n",
    "for name, cm in confusion_matrices.items():\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\n",
    "    plt.title(f\"Confusion Matrix for {name}\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZP--5ZNSlLw"
   },
   "source": [
    "# Loading Saved model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FryA8a9igzO"
   },
   "outputs": [],
   "source": [
    "#Load the saved model\n",
    "from joblib import load\n",
    "\n",
    "# Load each model individually\n",
    "# Give path of each model here\n",
    "logistic_regression_model = load(\"Logistic Regression_model.joblib\")\n",
    "random_forest_model = load(\"Random Forest_model.joblib\")\n",
    "svm_model = load(\"Support Vector Machine_model.joblib\")\n",
    "\n",
    "# Store the loaded models in a dictionary\n",
    "loaded_models = {\n",
    "    \"Logistic Regression\": logistic_regression_model,\n",
    "    \"Random Forest\": random_forest_model,\n",
    "    \"Support Vector Machine\": svm_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrKkHH-11HZK",
    "outputId": "e2c7bf3f-f6e1-48e3-c265-5cfb61d6a11f"
   },
   "outputs": [],
   "source": [
    "loaded_models.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "yn6NKiPgkjol",
    "outputId": "13dd7107-e312-4cef-c1a1-d07a92335b58"
   },
   "outputs": [],
   "source": [
    "# Load the encoders\n",
    "with open('encoder_src_ip.pkl', 'rb') as f:\n",
    "    loaded_encoder_src_ip = pickle.load(f)\n",
    "\n",
    "with open('encoder_dst_ip.pkl', 'rb') as f:\n",
    "    loaded_encoder_dst_ip = pickle.load(f)\n",
    "\n",
    "with open('encoder_label.pkl', 'rb') as f:\n",
    "    loaded_encoder_label = pickle.load(f)\n",
    "\n",
    "print(\"Encoders loaded successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRRkOik01yfg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nitxogSZ1yzg"
   },
   "source": [
    "##Preprocessing For Testing DATA Change Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "tGNzsOc3ujsD",
    "outputId": "0b7bcfd3-0bfe-4f48-d9da-0fa1c89861e0"
   },
   "outputs": [],
   "source": [
    "\n",
    "feature_columns = X_train.columns\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5b40kBNvA2eS"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3Sj2hcC16Za"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENgTyePU2MDI"
   },
   "outputs": [],
   "source": [
    "column_mapping = {'Flow ID': 'Flow ID',\n",
    " 'Src IP': ' Source IP',\n",
    " 'Src Port': ' Source Port',\n",
    " 'Dst IP': ' Destination IP',\n",
    " 'Dst Port': ' Destination Port',\n",
    " 'Protocol': ' Protocol',\n",
    " 'Timestamp': ' Timestamp',\n",
    " 'Flow Duration': ' Flow Duration',\n",
    " 'Tot Fwd Pkts': ' Total Fwd Packets',\n",
    " 'Tot Bwd Pkts': ' Total Backward Packets',\n",
    " 'TotLen Fwd Pkts': 'Total Length of Fwd Packets',\n",
    " 'TotLen Bwd Pkts': ' Total Length of Bwd Packets',\n",
    " 'Fwd Pkt Len Max': ' Fwd Packet Length Max',\n",
    " 'Fwd Pkt Len Min': ' Fwd Packet Length Min',\n",
    " 'Fwd Pkt Len Mean': ' Fwd Packet Length Mean',\n",
    " 'Fwd Pkt Len Std': ' Fwd Packet Length Std',\n",
    " 'Bwd Pkt Len Max': 'Bwd Packet Length Max',\n",
    " 'Bwd Pkt Len Min': ' Bwd Packet Length Min',\n",
    " 'Bwd Pkt Len Mean': ' Bwd Packet Length Mean',\n",
    " 'Bwd Pkt Len Std': ' Bwd Packet Length Std',\n",
    " 'Flow Byts/s': 'Flow Bytes/s',\n",
    " 'Flow Pkts/s': ' Flow Packets/s',\n",
    " 'Flow IAT Mean': ' Flow IAT Mean',\n",
    " 'Flow IAT Std': ' Flow IAT Std',\n",
    " 'Flow IAT Max': ' Flow IAT Max',\n",
    " 'Flow IAT Min': ' Flow IAT Min',\n",
    " 'Fwd IAT Tot': 'Fwd IAT Total',\n",
    " 'Fwd IAT Mean': ' Fwd IAT Mean',\n",
    " 'Fwd IAT Std': ' Fwd IAT Std',\n",
    " 'Fwd IAT Max': ' Fwd IAT Max',\n",
    " 'Fwd IAT Min': ' Fwd IAT Min',\n",
    " 'Bwd IAT Tot': 'Bwd IAT Total',\n",
    " 'Bwd IAT Mean': ' Bwd IAT Mean',\n",
    " 'Bwd IAT Std': ' Bwd IAT Std',\n",
    " 'Bwd IAT Max': ' Bwd IAT Max',\n",
    " 'Bwd IAT Min': ' Bwd IAT Min',\n",
    " 'Fwd PSH Flags': 'Fwd PSH Flags',\n",
    " 'Bwd PSH Flags': ' Bwd PSH Flags',\n",
    " 'Fwd URG Flags': ' Fwd URG Flags',\n",
    " 'Bwd URG Flags': ' Bwd URG Flags',\n",
    " 'Fwd Header Len': ' Fwd Header Length',\n",
    " 'Bwd Header Len': ' Bwd Header Length',\n",
    " 'Fwd Pkts/s': 'Fwd Packets/s',\n",
    " 'Bwd Pkts/s': ' Bwd Packets/s',\n",
    " 'Pkt Len Min': ' Min Packet Length',\n",
    " 'Pkt Len Max': ' Max Packet Length',\n",
    " 'Pkt Len Mean': ' Packet Length Mean',\n",
    " 'Pkt Len Std': ' Packet Length Std',\n",
    " 'Pkt Len Var': ' Packet Length Variance',\n",
    " 'FIN Flag Cnt': 'FIN Flag Count',\n",
    " 'SYN Flag Cnt': ' SYN Flag Count',\n",
    " 'RST Flag Cnt': ' RST Flag Count',\n",
    " 'PSH Flag Cnt': ' PSH Flag Count',\n",
    " 'ACK Flag Cnt': ' ACK Flag Count',\n",
    " 'URG Flag Cnt': ' URG Flag Count',\n",
    " 'CWE Flag Count': ' CWE Flag Count',\n",
    " 'ECE Flag Cnt': ' ECE Flag Count',\n",
    " 'Down/Up Ratio': ' Down/Up Ratio',\n",
    " 'Pkt Size Avg': ' Average Packet Size',\n",
    " 'Fwd Seg Size Avg': ' Avg Fwd Segment Size',\n",
    " 'Bwd Seg Size Avg': ' Avg Bwd Segment Size',\n",
    " 'Fwd Byts/b Avg': 'Fwd Avg Bytes/Bulk',\n",
    " 'Fwd Pkts/b Avg': ' Fwd Avg Packets/Bulk',\n",
    " 'Fwd Blk Rate Avg': ' Fwd Avg Bulk Rate',\n",
    " 'Bwd Byts/b Avg': ' Bwd Avg Bytes/Bulk',\n",
    " 'Bwd Pkts/b Avg': ' Bwd Avg Packets/Bulk',\n",
    " 'Bwd Blk Rate Avg': 'Bwd Avg Bulk Rate',\n",
    " 'Subflow Fwd Pkts': 'Subflow Fwd Packets',\n",
    " 'Subflow Fwd Byts': ' Subflow Fwd Bytes',\n",
    " 'Subflow Bwd Pkts': ' Subflow Bwd Packets',\n",
    " 'Subflow Bwd Byts': ' Subflow Bwd Bytes',\n",
    " 'Init Fwd Win Byts': 'Init_Win_bytes_forward',\n",
    " 'Init Bwd Win Byts': ' Init_Win_bytes_backward',\n",
    " 'Fwd Act Data Pkts': ' act_data_pkt_fwd',\n",
    " 'Fwd Seg Size Min': ' min_seg_size_forward',\n",
    " 'Active Mean': 'Active Mean',\n",
    " 'Active Std': ' Active Std',\n",
    " 'Active Max': ' Active Max',\n",
    " 'Active Min': ' Active Min',\n",
    " 'Idle Mean': 'Idle Mean',\n",
    " 'Idle Std': ' Idle Std',\n",
    " 'Idle Max': ' Idle Max',\n",
    " 'Idle Min': ' Idle Min',\n",
    " 'Label': 'Label'}\n",
    "\n",
    " # Function to standardize column names\n",
    "def standardize_columns(df, column_mapping):\n",
    "    # df = df.rename(columns=column_mapping)\n",
    "    if ' Label' in df.columns:\n",
    "        df = df.rename(columns={' Label': 'Label'})\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-qMOEq4Ed-J"
   },
   "outputs": [],
   "source": [
    "# specific_columns = [' Source IP', ' Source Port',' Destination IP', ' Destination Port', ' Protocol',\n",
    "#        ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
    "#        'Total Length of Fwd Packets', ' Total Length of Bwd Packets','Label']\n",
    "\n",
    "specific_columns = [' Source IP', ' Source Port',' Destination IP', ' Destination Port',\n",
    "       ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
    "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets','Label']\n",
    "\n",
    "# Standardize column names\n",
    "rename_dict = {\n",
    "    ' Source IP': 'src_ip', ' Source Port': 'src_port', ' Destination IP': 'dst_ip', ' Destination Port': 'dst_port',\n",
    "    ' Protocol': 'protocol', ' Flow Duration': 'flow_duration', ' Total Fwd Packets': 'total_fwd_packets',\n",
    "    ' Total Backward Packets': 'total_bwd_packets', 'Total Length of Fwd Packets': 'total_len_fwd_packets',\n",
    "    ' Total Length of Bwd Packets': 'total_len_bwd_packets', ' Label': 'label',\n",
    "\n",
    "    'srcip': 'src_ip', 'sport': 'src_port', 'dstip': 'dst_ip', 'dsport': 'dst_port',\n",
    "    'proto': 'protocol', 'dur': 'flow_duration', 'Spkts': 'total_fwd_packets', 'Dpkts': 'total_bwd_packets',\n",
    "    'sbytes': 'total_len_fwd_packets', 'dbytes': 'total_len_bwd_packets', 'Label': 'label'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWlWTIvr2rbr"
   },
   "outputs": [],
   "source": [
    "# column_mapping == column_mapping1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-D7xkdrRRujD"
   },
   "source": [
    "# Loading target dataset to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8rGrRtwi0uM",
    "outputId": "9ccf315b-1cd0-46ee-f5c3-c3d4ec5e850f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the new dataset we going to test the model on:\n",
    "url = \"https://ddosciu.s3.us-east-2.amazonaws.com/PCAPs/Test.csv\"\n",
    "#Test1\n",
    "url1 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/HTTP_Ddos.pcap_Flow.csv\"\n",
    "url2 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/amp.TCP.syn.optionallyACK.optionallysamePort.pcapng_Flow.csv\"\n",
    "url3 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/amp.TCP.reflection.SYNACK.pcap_Flow.csv\"\n",
    "url4 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/amp.UDP.bacnet.IOT.37810.pcapng_Flow.csv\"\n",
    "url5 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/1.pcap_Flow.csv\"\n",
    "\n",
    "url6 =\"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/amp.dns.RRSIG.fragmented.pcap_Flow.csv\"\n",
    "url7 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/amp.UDP.isakmp.pcap_Flow.csv\"\n",
    "url8 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/pkt.ICMP.largeempty.pcap_Flow.csv\"\n",
    "url9 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/pkt.TCP.DOMINATE.syn.ecn.cwr.pcapng_Flow.csv\"\n",
    "url10 = \"/content/NormalTraffic2.pcap_Flow.csv\"\n",
    "url11= \"https://ddosciu.s3.us-east-2.amazonaws.com/IC_Taraf.root.1.pcap_Flow.csv\"\n",
    "\n",
    "url12 = \"/content/drive/MyDrive/online_tasks/Portmap.csv\"\n",
    "\n",
    "\n",
    "url13 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/Train.csv\"\n",
    "url14 = \"/content/drive/MyDrive/online_tasks/UNSW-NB15_4.csv\"\n",
    "url15 = \"/content/drive/MyDrive/online_tasks/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\"\n",
    "\n",
    "url16 = 'https://ddosciu.s3.us-east-2.amazonaws.com/UDP.csv'\n",
    "\n",
    "new_data = pd.read_csv(url16)\n",
    "\n",
    "\n",
    "# Apply the column mapping to the testing data\n",
    "new_data = standardize_columns(new_data, column_mapping)\n",
    "\n",
    "new_data = new_data.rename(columns=column_mapping)\n",
    "# new_data = data_2.copy()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "T6TR_h2Zp-4I",
    "outputId": "583cb591-6453-46b5-af85-bdec3d8e1e57"
   },
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cW1WNCBjE8zh",
    "outputId": "2aaa28b2-ea4d-4f70-b5d9-93162ecee649"
   },
   "outputs": [],
   "source": [
    "new_data = new_data[specific_columns]\n",
    "\n",
    "new_data.rename(columns=rename_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqceS9yXcfUA",
    "outputId": "ec870eb7-3db3-481e-b4ec-108e46e0eb7e"
   },
   "outputs": [],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ov3Qy0oQcUuv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osEj0ittA4Ts",
    "outputId": "24468477-e723-4490-dfb7-395581c50394"
   },
   "outputs": [],
   "source": [
    "len(X.columns),len(new_data.columns)\n",
    "# Check for missing columns in new_data compared to train data X\n",
    "missing_columns = set(X.columns) - set(new_data.columns)\n",
    "\n",
    "# Check for missing columns in train data X compared to new_data\n",
    "extra_columns = set(new_data.columns) - set(X.columns)\n",
    "\n",
    "print(\"Columns missing in new_data:\", missing_columns)\n",
    "print(\"Columns extra in new_data:\", extra_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRgQReS8QGkK"
   },
   "outputs": [],
   "source": [
    "# new_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6Hmz79GADRW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "6S-vpcNyCqcl",
    "outputId": "5abb58ff-afa3-4a73-db94-427fbae2b5f4"
   },
   "outputs": [],
   "source": [
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaMqYH8C_XAh"
   },
   "outputs": [],
   "source": [
    "# Transform the test data using the loaded encoders\n",
    "# new_data['src_ip'] = loaded_encoder_src_ip.transform(new_data['src_ip'])\n",
    "# new_data['dst_ip'] = loaded_encoder_dst_ip.transform(new_data['dst_ip'])\n",
    "# new_data['label'] = loaded_encoder_label.transform(new_data['label'])\n",
    "\n",
    "\n",
    "# # Encode categorical features (e.g., IP addresses)\n",
    "# encoder = LabelEncoder()\n",
    "# new_data['src_ip'] = encoder.fit_transform(new_data['src_ip'])\n",
    "# new_data['dst_ip'] = encoder.fit_transform(new_data['dst_ip'])\n",
    "# # new_data['protocol'] = encoder.fit_transform(new_data['protocol'])\n",
    "# new_data['label'] = encoder.fit_transform(new_data['label'])\n",
    "# new_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "id": "nFH_Hg9zmDY3",
    "outputId": "020b9cc6-042b-4a57-8665-70b6ed8db052"
   },
   "outputs": [],
   "source": [
    "# Create separate LabelEncoders for each categorical feature\n",
    "encoder_src_ip = LabelEncoder()\n",
    "encoder_dst_ip = LabelEncoder()\n",
    "encoder_src_port = LabelEncoder()\n",
    "encoder_dst_port = LabelEncoder()\n",
    "\n",
    "encoder_label = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical features\n",
    "new_data['src_ip'] = encoder_src_ip.fit_transform(new_data['src_ip'])\n",
    "new_data['dst_ip'] = encoder_dst_ip.fit_transform(new_data['dst_ip'])\n",
    "new_data['src_port'] = encoder_src_port.fit_transform(new_data['src_port'])\n",
    "new_data['dst_port'] = encoder_dst_port.fit_transform(new_data['dst_port'].astype(str))\n",
    "\n",
    "new_data['label'] = encoder_label.fit_transform(new_data['label'])\n",
    "new_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xpQU2yfiNcb",
    "outputId": "2d3f5dba-66cc-46dd-e50f-b6b8da6837be"
   },
   "outputs": [],
   "source": [
    "set(new_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GAUlYXvvtw9O",
    "outputId": "c3ee8de5-822f-45ca-9088-5bacabb79181"
   },
   "outputs": [],
   "source": [
    "# Inspect the mapping between original labels and encoded numbers\n",
    "print(\"Mapping between original labels and encoded numbers:\")\n",
    "for label, encoded_label in zip(encoder_label.classes_, encoder_label.transform(encoder_label.classes_)):\n",
    "    print(f\"{label}: {encoded_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hsdj1VWT_gtK"
   },
   "outputs": [],
   "source": [
    "X_new = new_data.drop('label', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w3vyogQb8iE"
   },
   "outputs": [],
   "source": [
    "X_new.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_new = imputer.fit_transform(X_new)\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)\n",
    "\n",
    "#Labels for comparison (They are not always available for some datasets)\n",
    "y_new = new_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hc83C6eK_XjD",
    "outputId": "f87b8a18-261a-41ce-ad41-a331c9b262dc"
   },
   "outputs": [],
   "source": [
    "y_new.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz2fc-oDBfw_"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JXtxYcPwmnnR",
    "outputId": "3e9fb9f9-b807-44ba-f4d2-3a500fb2da16"
   },
   "outputs": [],
   "source": [
    "# Now, i can use the loaded models to make predictions on the preprocessed new dataset\n",
    "predictions = {}\n",
    "for name, model in loaded_models.items():\n",
    "    predictions[name] = model.predict(X_new)\n",
    "\n",
    "# Print predictions for each model\n",
    "for name, preds in predictions.items():\n",
    "    print(f\"Predictions using {name}: {preds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcW6mhPs7cb1",
    "outputId": "4d49b067-7992-4d33-fe04-161dc9a34fbb"
   },
   "outputs": [],
   "source": [
    "# Define a mapping from encoded labels to original labels\n",
    "label_mapping = {0: 'BENIGN', 1: 'LDAP', 2: 'NetBIOS'}\n",
    "\n",
    "# Now, you can use the loaded models to make predictions on the preprocessed new dataset\n",
    "predictions = {}\n",
    "\n",
    "# Iterate through each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions using the current model\n",
    "    preds = model.predict(X_new)\n",
    "    # Map encoded predictions to their original labels\n",
    "    mapped_preds = [label_mapping[pred] for pred in preds]\n",
    "    # Store the mapped predictions\n",
    "    predictions[name] = mapped_preds\n",
    "\n",
    "# Print mapped predictions for each model\n",
    "for name, preds in predictions.items():\n",
    "    print(f\"Predictions using {name}: {preds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "Q_VVt80c9hIN",
    "outputId": "8e2cf72a-51c1-4f56-972b-d1fb34c6c914"
   },
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame\n",
    "all_predictions_df = pd.DataFrame()\n",
    "\n",
    "# Initialize a list to store model names\n",
    "model_names = []\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_new)\n",
    "\n",
    "    # Map the predicted labels\n",
    "    mapped_predictions = [label_mapping[label] for label in y_pred]\n",
    "\n",
    "    # Add the model name to the list\n",
    "    model_names.append(name)\n",
    "\n",
    "    # Create a DataFrame for predicted labels\n",
    "    predicted_labels_df = pd.DataFrame({'Predicted_Label': y_pred, 'Mapped_Prediction': mapped_predictions})\n",
    "\n",
    "    # Add the DataFrame to the overall DataFrame\n",
    "    all_predictions_df = pd.concat([all_predictions_df, predicted_labels_df], axis=1)\n",
    "\n",
    "# Set the column names for the first row\n",
    "all_predictions_df.columns = pd.MultiIndex.from_product([model_names, ['Predicted_Label', 'Mapped_Prediction']])\n",
    "\n",
    "# Print the DataFrame\n",
    "all_predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eG2zx34aBmDG",
    "outputId": "6026e667-9c1f-4a3f-e1f9-b881938ef959"
   },
   "outputs": [],
   "source": [
    "# Define a mapping from encoded labels to original labels\n",
    "label_mapping = {0: 'No Attack'}\n",
    "\n",
    "# Now, you can use the loaded models to make predictions on the preprocessed new dataset\n",
    "predictions = {}\n",
    "\n",
    "# Iterate through each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions using the current model\n",
    "    preds = model.predict(X_new)\n",
    "    # Map encoded predictions to their original labels\n",
    "    mapped_preds = ['No Attack' if pred == 0 else 'DDos Attack' for pred in preds]\n",
    "    # Store the mapped predictions\n",
    "    predictions[name] = mapped_preds\n",
    "\n",
    "# Print mapped predictions for each model\n",
    "for name, preds in predictions.items():\n",
    "    print(f\"Predictions using {name}: {preds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPoaPmgb1n68",
    "outputId": "f063be74-3bff-4cdd-d323-ba023ad017fc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Define a mapping from encoded labels to original labels\n",
    "label_mapping = {0: 'No Attack', 1: 'DDoS Attack'}\n",
    "\n",
    "# Placeholder for predictions, accuracies, and confusion matrices\n",
    "predictions = {}\n",
    "accuracies = {}\n",
    "confusion_matrices = {}\n",
    "\n",
    "# Iterate through each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions using the current model\n",
    "    preds = model.predict(X_new)\n",
    "\n",
    "    # Store the predictions\n",
    "    predictions[name] = preds\n",
    "\n",
    "    # Calculate accuracy using numeric labels\n",
    "    accuracy = accuracy_score(y_new, preds)\n",
    "    accuracies[name] = accuracy\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_new, preds)\n",
    "    confusion_matrices[name] = cm\n",
    "\n",
    "    # Map encoded predictions to their original labels for display\n",
    "    mapped_preds = [label_mapping[pred] for pred in preds]\n",
    "\n",
    "    # Print mapped predictions for each model\n",
    "    print(f\"Predictions using {name}: {mapped_preds[:10]}...\")  # Print only the first 10 for brevity\n",
    "    print(f\"Accuracy for {name}: {accuracy:.4f}\")\n",
    "    print(f\"Confusion Matrix for {name}:\\n{cm}\\n\")\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for each model:\")\n",
    "for name, accuracy in accuracies.items():\n",
    "    print(f\"{name}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lvS_9wJ2tj0",
    "outputId": "e51dc537-9970-4d42-b58f-ae9ad7163cf9"
   },
   "outputs": [],
   "source": [
    "# Check class distribution in the training data\n",
    "print(\"Class distribution in y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# Check class distribution in the test data\n",
    "print(\"Class distribution in y_new:\")\n",
    "print(pd.Series(y_new).value_counts())\n",
    "\n",
    "# Make predictions and calculate accuracy and confusion matrix for each model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define a mapping from encoded labels to original labels\n",
    "label_mapping = {0: 'No Attack', 1: 'DDoS Attack'}\n",
    "\n",
    "# Placeholder for predictions, accuracies, and confusion matrices\n",
    "predictions = {}\n",
    "accuracies = {}\n",
    "confusion_matrices = {}\n",
    "\n",
    "# Iterate through each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions using the current model\n",
    "    preds = model.predict(X_new)\n",
    "\n",
    "    # Store the predictions\n",
    "    predictions[name] = preds\n",
    "\n",
    "    # Calculate accuracy using numeric labels\n",
    "    accuracy = accuracy_score(y_new, preds)\n",
    "    accuracies[name] = accuracy\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_new, preds)\n",
    "    confusion_matrices[name] = cm\n",
    "\n",
    "    # Map encoded predictions to their original labels for display\n",
    "    mapped_preds = [label_mapping[pred] for pred in preds]\n",
    "\n",
    "    # Print mapped predictions for each model\n",
    "    print(f\"Predictions using {name}: {mapped_preds[:10]}...\")  # Print only the first 10 for brevity\n",
    "    print(f\"Accuracy for {name}: {accuracy:.4f}\")\n",
    "    print(f\"Confusion Matrix for {name}:\\n{cm}\\n\")\n",
    "    print(f\"Classification Report for {name}:\\n{classification_report(y_new, preds, target_names=list(label_mapping.values()))}\\n\")\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for each model:\")\n",
    "for name, accuracy in accuracies.items():\n",
    "    print(f\"{name}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "NKhmYD31BpEO",
    "outputId": "ca4eb41a-2ed2-4c91-8dda-b2d286e8a54b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "all_predictions_df = pd.DataFrame()\n",
    "\n",
    "# Initialize a list to store model names\n",
    "model_names = []\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_new)\n",
    "\n",
    "    # Map the predicted labels\n",
    "    mapped_predictions = ['No Attack' if label == 0 else 'Attack' for label in y_pred]\n",
    "\n",
    "    # Add the model name to the list\n",
    "    model_names.append(name)\n",
    "\n",
    "    # Create a DataFrame for predicted labels\n",
    "    predicted_labels_df = pd.DataFrame({'Predicted_Label': y_pred, 'Mapped_Prediction': mapped_predictions})\n",
    "\n",
    "    # Add the DataFrame to the overall DataFrame\n",
    "    all_predictions_df = pd.concat([all_predictions_df, predicted_labels_df], axis=1)\n",
    "\n",
    "# Set the column names for the first row\n",
    "all_predictions_df.columns = pd.MultiIndex.from_product([model_names, ['Predicted_Label', 'Mapped_Prediction']])\n",
    "\n",
    "# Print the DataFrame\n",
    "all_predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vlj-IcPcHC7q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCUmsOnPHIkf"
   },
   "outputs": [],
   "source": [
    "#Savinf model prediction to CSV file\n",
    "all_predictions_df.to_csv('test_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuYSrD_DranY",
    "outputId": "b31af589-4dd8-4d52-e128-c6c494e7e4a0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_new and y_new are already defined\n",
    "# Example:\n",
    "# X_new = ...\n",
    "# y_new = ...\n",
    "\n",
    "# Initialize an empty DataFrame for predictions\n",
    "all_predictions_df = pd.DataFrame()\n",
    "\n",
    "# Initialize a list to store model names and accuracies\n",
    "model_names = []\n",
    "accuracies = []\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_new)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_new, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Map the predicted labels\n",
    "    mapped_predictions = ['No Attack' if label == 0 else 'Attack' for label in y_pred]\n",
    "\n",
    "    # Add the model name to the list\n",
    "    model_names.append(name)\n",
    "\n",
    "    # Create a DataFrame for predicted labels\n",
    "    predicted_labels_df = pd.DataFrame({'Predicted_Label': y_pred, 'Mapped_Prediction': mapped_predictions})\n",
    "\n",
    "    # Add the DataFrame to the overall DataFrame\n",
    "    all_predictions_df = pd.concat([all_predictions_df, predicted_labels_df], axis=1)\n",
    "\n",
    "# Set the column names for the first row\n",
    "all_predictions_df.columns = pd.MultiIndex.from_product([model_names, ['Predicted_Label', 'Mapped_Prediction']])\n",
    "\n",
    "# Create a DataFrame for accuracies\n",
    "accuracy_df = pd.DataFrame({'Model': model_names, 'Accuracy': accuracies})\n",
    "\n",
    "# Print the predictions DataFrame\n",
    "print(all_predictions_df)\n",
    "\n",
    "# Print the accuracies DataFrame\n",
    "print(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QQ1c7dXhiLj",
    "outputId": "33ff9f8f-a90c-4057-dacc-60a2fab9c147"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTC0YRQQogkO"
   },
   "outputs": [],
   "source": [
    "# #Manual label part\n",
    "# import pandas as pd\n",
    "\n",
    "# # Initialize an empty DataFrame\n",
    "# all_predictions_df = pd.DataFrame()\n",
    "\n",
    "# # Initialize a list to store model names\n",
    "# model_names = []\n",
    "\n",
    "# # Assign manual labels (all zeros) based on the length of X_new\n",
    "# manual_labels = [1,2] * len(X_new)\n",
    "\n",
    "# # Iterate over each loaded model\n",
    "# for name, model in loaded_models.items():\n",
    "#     # Make predictions on test data\n",
    "#     y_pred = model.predict(X_new)\n",
    "\n",
    "#     # Map the predicted labels\n",
    "#     mapped_predictions = ['No Attack' if label == 0 else 'Attack' for label in y_pred]\n",
    "\n",
    "#     # Calculate accuracy\n",
    "#     accuracy = sum(1 for pred, true in zip(y_pred, manual_labels) if pred == true) / len(manual_labels)\n",
    "\n",
    "#     # Print accuracy for each model\n",
    "#     print(f\"Accuracy for {name}: {accuracy}\")\n",
    "\n",
    "#     # Add the model name to the list\n",
    "#     model_names.append(name)\n",
    "\n",
    "#     # Create a DataFrame for predicted labels\n",
    "#     predicted_labels_df = pd.DataFrame({'Predicted_Label': y_pred, 'Mapped_Prediction': mapped_predictions})\n",
    "\n",
    "#     # Add the DataFrame to the overall DataFrame\n",
    "#     all_predictions_df = pd.concat([all_predictions_df, predicted_labels_df], axis=1)\n",
    "\n",
    "# # Set the column names for the first row\n",
    "# all_predictions_df.columns = pd.MultiIndex.from_product([model_names, ['Predicted_Label', 'Mapped_Prediction']])\n",
    "\n",
    "# # Print the DataFrame\n",
    "# print(all_predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHYD57H4rC8A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3SsEwF3ORQ78",
    "outputId": "8580c96e-592d-4802-9dac-19160b98ba87"
   },
   "outputs": [],
   "source": [
    "#Manual label part\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "all_predictions_df = pd.DataFrame()\n",
    "\n",
    "# Initialize a list to store model names\n",
    "model_names = []\n",
    "\n",
    "# Assign manual labels (all zeros) based on the length of X_new\n",
    "manual_labels = y_new\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_new)\n",
    "\n",
    "    # Map the predicted labels\n",
    "    mapped_predictions = ['No Attack' if label == 0 else 'Attack' for label in y_pred]\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = sum(1 for pred, true in zip(y_pred, manual_labels) if pred == true) / len(manual_labels)\n",
    "\n",
    "    # Print accuracy for each model\n",
    "    print(f\"Accuracy for {name}: {accuracy}\")\n",
    "\n",
    "    # Add the model name to the list\n",
    "    model_names.append(name)\n",
    "\n",
    "    # Create a DataFrame for predicted labels\n",
    "    predicted_labels_df = pd.DataFrame({'Predicted_Label': y_pred, 'Mapped_Prediction': mapped_predictions})\n",
    "\n",
    "    # Add the DataFrame to the overall DataFrame\n",
    "    all_predictions_df = pd.concat([all_predictions_df, predicted_labels_df], axis=1)\n",
    "\n",
    "# Set the column names for the first row\n",
    "all_predictions_df.columns = pd.MultiIndex.from_product([model_names, ['Predicted_Label', 'Mapped_Prediction']])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(all_predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FQ5vngRkrYUk",
    "outputId": "3e0cfef4-5655-4da6-b657-93a76b91bf3c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the DataFrame to store model comparison\n",
    "model_comparison = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"F1 Score\"])\n",
    "\n",
    "# Initialize dictionary to store confusion matrices\n",
    "confusion_matrices = {}\n",
    "\n",
    "# Initialize lists to store accuracy and F1 score for each model\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_new)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_new, y_pred)\n",
    "    f1 = f1_score(y_new, y_pred, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_new, y_pred)\n",
    "    confusion_matrices[name] = cm\n",
    "\n",
    "    # Append results to model comparison DataFrame\n",
    "    model_comparison = model_comparison._append({\"Model\": name, \"Accuracy\": accuracy, \"F1 Score\": f1}, ignore_index=True)\n",
    "\n",
    "    # Append accuracy and F1 score to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print model evaluation metrics and confusion matrix\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 score: {f1}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_new, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Plotting accuracy scores\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(model_comparison['Model'], accuracy_scores, color='skyblue')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting F1 scores\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(model_comparison['Model'], f1_scores, color='orange')\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Displaying the model comparison DataFrame\n",
    "print(\"Model Comparison:\")\n",
    "print(model_comparison)\n",
    "\n",
    "# Plot confusion matrices for each model using Seaborn\n",
    "for name, cm in confusion_matrices.items():\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\n",
    "    plt.title(f\"Confusion Matrix for {name}\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxcP6YX1slCN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
