{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "urkkDPRZ3kiK",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "# Load and Train the desire testing dataset files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Be-80uIesm83",
    "outputId": "efb70b8e-0adc-4e98-bb4c-75443c2ceb2c",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_9892/3660324814.py:12: DtypeWarning: Columns (85) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  data = pd.read_csv(\"https://ddosciu.s3.us-east-2.amazonaws.com/Portmap.csv\")\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.metrics import classification_report, accuracy_score, f1_score\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# data = pd.read_csv('https://ddosciu.s3.us-east-2.amazonaws.com/CSVs/UNB/Portmap.csv')\n",
    "# data = pd.read_csv('https://unsw-my.sharepoint.com/:x:/r/personal/z5025758_ad_unsw_edu_au/_layouts/15/Doc.aspx?sourcedoc=%7B2A810F6A-CC3D-4D98-909E-37489D8DAF98%7D&file=UNSW_NB15_testing-set.csv&action=default&mobileredirect=true')\n",
    "data = pd.read_csv(\"https://ddosciu.s3.us-east-2.amazonaws.com/Portmap.csv\")\n",
    "data_2 = pd.read_csv(\"https://ddosciu.s3.us-east-2.amazonaws.com/UNSW-NB15_4.csv\")\n",
    "data_3 = pd.read_csv(\"https://ddosciu.s3.us-east-2.amazonaws.com/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SvmFf5QQMATU",
    "tags": []
   },
   "source": [
    "# Pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SMPU8utHMMvF",
    "tags": []
   },
   "source": [
    "## Dataset1 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "9Q4GgIqjLt1N",
    "outputId": "aed421e2-28f8-4c09-b868-5536dafb26ef"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Flow ID</th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Protocol</th>\n",
       "      <th>Timestamp</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>...</th>\n",
       "      <th>Active Std</th>\n",
       "      <th>Active Max</th>\n",
       "      <th>Active Min</th>\n",
       "      <th>Idle Mean</th>\n",
       "      <th>Idle Std</th>\n",
       "      <th>Idle Max</th>\n",
       "      <th>Idle Min</th>\n",
       "      <th>SimillarHTTP</th>\n",
       "      <th>Inbound</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>24</td>\n",
       "      <td>192.168.50.254-224.0.0.5-0-0-0</td>\n",
       "      <td>192.168.50.254</td>\n",
       "      <td>0</td>\n",
       "      <td>224.0.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-03 09:18:16.964447</td>\n",
       "      <td>114456999</td>\n",
       "      <td>45</td>\n",
       "      <td>...</td>\n",
       "      <td>28337.112288</td>\n",
       "      <td>98168.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>9529897.25</td>\n",
       "      <td>351582.631269</td>\n",
       "      <td>10001143.0</td>\n",
       "      <td>9048097.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>26</td>\n",
       "      <td>192.168.50.253-224.0.0.5-0-0-0</td>\n",
       "      <td>192.168.50.253</td>\n",
       "      <td>0</td>\n",
       "      <td>224.0.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2018-11-03 09:18:18.506537</td>\n",
       "      <td>114347504</td>\n",
       "      <td>56</td>\n",
       "      <td>...</td>\n",
       "      <td>121314.911865</td>\n",
       "      <td>420255.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>9493929.75</td>\n",
       "      <td>351541.079539</td>\n",
       "      <td>9978130.0</td>\n",
       "      <td>8820294.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>176563</td>\n",
       "      <td>172.217.10.98-192.168.50.6-443-54799-6</td>\n",
       "      <td>192.168.50.6</td>\n",
       "      <td>54799</td>\n",
       "      <td>172.217.10.98</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-11-03 09:18:18.610576</td>\n",
       "      <td>36435473</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62416.0</td>\n",
       "      <td>62416.0</td>\n",
       "      <td>36373056.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36373056.0</td>\n",
       "      <td>36373056.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>50762</td>\n",
       "      <td>172.217.7.2-192.168.50.6-443-54800-6</td>\n",
       "      <td>192.168.50.6</td>\n",
       "      <td>54800</td>\n",
       "      <td>172.217.7.2</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-11-03 09:18:18.610579</td>\n",
       "      <td>36434705</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62413.0</td>\n",
       "      <td>62413.0</td>\n",
       "      <td>36372291.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36372291.0</td>\n",
       "      <td>36372291.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>87149</td>\n",
       "      <td>172.217.10.98-192.168.50.6-443-54801-6</td>\n",
       "      <td>192.168.50.6</td>\n",
       "      <td>54801</td>\n",
       "      <td>172.217.10.98</td>\n",
       "      <td>443</td>\n",
       "      <td>6</td>\n",
       "      <td>2018-11-03 09:18:18.610581</td>\n",
       "      <td>36434626</td>\n",
       "      <td>6</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>62409.0</td>\n",
       "      <td>62409.0</td>\n",
       "      <td>36372216.00</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>36372216.0</td>\n",
       "      <td>36372216.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 88 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                 Flow ID       Source IP  \\\n",
       "0          24          192.168.50.254-224.0.0.5-0-0-0  192.168.50.254   \n",
       "1          26          192.168.50.253-224.0.0.5-0-0-0  192.168.50.253   \n",
       "2      176563  172.217.10.98-192.168.50.6-443-54799-6    192.168.50.6   \n",
       "3       50762    172.217.7.2-192.168.50.6-443-54800-6    192.168.50.6   \n",
       "4       87149  172.217.10.98-192.168.50.6-443-54801-6    192.168.50.6   \n",
       "\n",
       "    Source Port  Destination IP   Destination Port   Protocol  \\\n",
       "0             0       224.0.0.5                  0          0   \n",
       "1             0       224.0.0.5                  0          0   \n",
       "2         54799   172.217.10.98                443          6   \n",
       "3         54800     172.217.7.2                443          6   \n",
       "4         54801   172.217.10.98                443          6   \n",
       "\n",
       "                    Timestamp   Flow Duration   Total Fwd Packets  ...  \\\n",
       "0  2018-11-03 09:18:16.964447       114456999                  45  ...   \n",
       "1  2018-11-03 09:18:18.506537       114347504                  56  ...   \n",
       "2  2018-11-03 09:18:18.610576        36435473                   6  ...   \n",
       "3  2018-11-03 09:18:18.610579        36434705                   6  ...   \n",
       "4  2018-11-03 09:18:18.610581        36434626                   6  ...   \n",
       "\n",
       "      Active Std   Active Max   Active Min    Idle Mean       Idle Std  \\\n",
       "0   28337.112288      98168.0          3.0   9529897.25  351582.631269   \n",
       "1  121314.911865     420255.0          4.0   9493929.75  351541.079539   \n",
       "2       0.000000      62416.0      62416.0  36373056.00       0.000000   \n",
       "3       0.000000      62413.0      62413.0  36372291.00       0.000000   \n",
       "4       0.000000      62409.0      62409.0  36372216.00       0.000000   \n",
       "\n",
       "     Idle Max    Idle Min  SimillarHTTP   Inbound   Label  \n",
       "0  10001143.0   9048097.0             0         0  BENIGN  \n",
       "1   9978130.0   8820294.0             0         0  BENIGN  \n",
       "2  36373056.0  36373056.0             0         0  BENIGN  \n",
       "3  36372291.0  36372291.0             0         0  BENIGN  \n",
       "4  36372216.0  36372216.0             0         0  BENIGN  \n",
       "\n",
       "[5 rows x 88 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "1zvZB0tfSSyF"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'Flow ID', ' Source IP', ' Source Port',\n",
       "       ' Destination IP', ' Destination Port', ' Protocol', ' Timestamp',\n",
       "       ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
       "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
       "       ' Fwd Packet Length Max', ' Fwd Packet Length Min',\n",
       "       ' Fwd Packet Length Mean', ' Fwd Packet Length Std',\n",
       "       'Bwd Packet Length Max', ' Bwd Packet Length Min',\n",
       "       ' Bwd Packet Length Mean', ' Bwd Packet Length Std', 'Flow Bytes/s',\n",
       "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
       "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
       "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
       "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags',\n",
       "       ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags',\n",
       "       ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s',\n",
       "       ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length',\n",
       "       ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance',\n",
       "       'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count',\n",
       "       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n",
       "       ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio',\n",
       "       ' Average Packet Size', ' Avg Fwd Segment Size',\n",
       "       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk',\n",
       "       ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk',\n",
       "       ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
       "       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n",
       "       'Init_Win_bytes_forward', ' Init_Win_bytes_backward',\n",
       "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean',\n",
       "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
       "       ' Idle Max', ' Idle Min', 'SimillarHTTP', ' Inbound', ' Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "Am30-F0PhEXd"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192.168.50.254</td>\n",
       "      <td>0</td>\n",
       "      <td>224.0.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>114456999</td>\n",
       "      <td>45</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.50.253</td>\n",
       "      <td>0</td>\n",
       "      <td>224.0.0.5</td>\n",
       "      <td>0</td>\n",
       "      <td>114347504</td>\n",
       "      <td>56</td>\n",
       "      <td>0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.168.50.6</td>\n",
       "      <td>54799</td>\n",
       "      <td>172.217.10.98</td>\n",
       "      <td>443</td>\n",
       "      <td>36435473</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>192.168.50.6</td>\n",
       "      <td>54800</td>\n",
       "      <td>172.217.7.2</td>\n",
       "      <td>443</td>\n",
       "      <td>36434705</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192.168.50.6</td>\n",
       "      <td>54801</td>\n",
       "      <td>172.217.10.98</td>\n",
       "      <td>443</td>\n",
       "      <td>36434626</td>\n",
       "      <td>6</td>\n",
       "      <td>2</td>\n",
       "      <td>116.0</td>\n",
       "      <td>92.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        Source IP   Source Port  Destination IP   Destination Port  \\\n",
       "0  192.168.50.254             0       224.0.0.5                  0   \n",
       "1  192.168.50.253             0       224.0.0.5                  0   \n",
       "2    192.168.50.6         54799   172.217.10.98                443   \n",
       "3    192.168.50.6         54800     172.217.7.2                443   \n",
       "4    192.168.50.6         54801   172.217.10.98                443   \n",
       "\n",
       "    Flow Duration   Total Fwd Packets   Total Backward Packets  \\\n",
       "0       114456999                  45                        0   \n",
       "1       114347504                  56                        0   \n",
       "2        36435473                   6                        2   \n",
       "3        36434705                   6                        2   \n",
       "4        36434626                   6                        2   \n",
       "\n",
       "   Total Length of Fwd Packets   Total Length of Bwd Packets   Label  \n",
       "0                          0.0                           0.0       0  \n",
       "1                          0.0                           0.0       0  \n",
       "2                        116.0                          92.0       0  \n",
       "3                        116.0                          92.0       0  \n",
       "4                        116.0                          92.0       0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data = data[[' Source IP', ' Source Port',' Destination IP', ' Destination Port', ' Protocol',\n",
    "#        ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
    "#        'Total Length of Fwd Packets', ' Total Length of Bwd Packets',' Label']]\n",
    "\n",
    "data = data[[' Source IP', ' Source Port',' Destination IP', ' Destination Port',\n",
    "       ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
    "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',' Label']]\n",
    "\n",
    "# Map labels in data_1 to binary\n",
    "data[' Label'] = data[' Label'].map({\n",
    "    'BENIGN': 0,\n",
    "    'Portmap': 1})\n",
    "\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "ETVxFV9obG4U"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    186960\n",
       "0      4734\n",
       "Name:  Label, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "MdJaHrHMb3Xz"
   },
   "outputs": [],
   "source": [
    "# # Set the desired number of majority class samples\n",
    "# num_majority_samples = 20000 #100000\n",
    "#\n",
    "# # Get the minority class label\n",
    "# minority_class = data[' Label'].value_counts().idxmin()\n",
    "\n",
    "# # Separate majority and minority class samples\n",
    "# majority_samples = data[data[' Label'] != minority_class]\n",
    "# minority_samples = data[data[' Label'] == minority_class]\n",
    "\n",
    "# # Sample the majority class samples\n",
    "# majority_samples_sampled = majority_samples.sample(num_majority_samples, random_state=42)\n",
    "\n",
    "# # Combine the sampled majority class samples and minority class samples\n",
    "# balanced_data = pd.concat([majority_samples_sampled, minority_samples], axis=0)\n",
    "\n",
    "# # Shuffle the balanced dataset\n",
    "# balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# balanced_data.head()\n",
    "# num_unique_labels = balanced_data[' Label'].nunique()\n",
    "# print(\"Number of unique labels in the balanced data:\", num_unique_labels)\n",
    "# label_frequency = balanced_data[' Label'].value_counts()\n",
    "# print(\"Frequency of each unique label in the balanced data:\")\n",
    "# print(label_frequency)\n",
    "# label_frequency_data = data[' Label'].value_counts()\n",
    "# print(\"Frequency of each unique label in the original data:\")\n",
    "# print(label_frequency_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ciHA5fClpP6_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels in the balanced data: 2\n",
      "Frequency of each unique label in the balanced data:\n",
      "1    15000\n",
      "0    15000\n",
      "Name:  Label, dtype: int64\n",
      "Frequency of each unique label in the original data:\n",
      "1    186960\n",
      "0      4734\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Set the desired number of majority class samples\n",
    "num_majority_samples = 15000  # Adjust this number as needed\n",
    "\n",
    "# Get the minority class label\n",
    "minority_class = data[' Label'].value_counts().idxmin()\n",
    "\n",
    "# Separate majority and minority class samples\n",
    "majority_samples = data[data[' Label'] != minority_class]\n",
    "minority_samples = data[data[' Label'] == minority_class]\n",
    "\n",
    "# Sample the majority class samples\n",
    "majority_samples_sampled = majority_samples.sample(num_majority_samples, random_state=42)\n",
    "\n",
    "# Upsample the minority class samples\n",
    "minority_samples_upsampled = resample(\n",
    "    minority_samples,\n",
    "    replace=True,  # Sample with replacement\n",
    "    n_samples=num_majority_samples,  # Match the number of majority samples\n",
    "    random_state=42  # Reproducible results\n",
    ")\n",
    "\n",
    "# Combine the sampled majority class samples and upsampled minority class samples\n",
    "balanced_data = pd.concat([majority_samples_sampled, minority_samples_upsampled], axis=0)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_data = balanced_data.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print some information about the balanced dataset\n",
    "balanced_data.head()\n",
    "num_unique_labels = balanced_data[' Label'].nunique()\n",
    "print(\"Number of unique labels in the balanced data:\", num_unique_labels)\n",
    "label_frequency = balanced_data[' Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the balanced data:\")\n",
    "print(label_frequency)\n",
    "label_frequency_data = data[' Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the original data:\")\n",
    "print(label_frequency_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "NzNu3IMeaYH-"
   },
   "outputs": [],
   "source": [
    "data=balanced_data.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "S3n-wgNGMWH3",
    "tags": []
   },
   "source": [
    "## Dataset2 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "UeX0y2rTACvI"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['srcip', 'sport', 'dstip', 'dsport', 'proto', 'state', 'dur', 'sbytes',\n",
       "       'dbytes', 'sttl', 'dttl', 'sloss', 'dloss', 'service', 'Sload', 'Dload',\n",
       "       'Spkts', 'Dpkts', 'swin', 'dwin', 'stcpb', 'dtcpb', 'smeansz',\n",
       "       'dmeansz', 'trans_depth', 'res_bdy_len', 'Sjit', 'Djit', 'Stime',\n",
       "       'Ltime', 'Sintpkt', 'Dintpkt', 'tcprtt', 'synack', 'ackdat',\n",
       "       'is_sm_ips_ports', 'ct_state_ttl', 'ct_flw_http_mthd', 'is_ftp_login',\n",
       "       'ct_ftp_cmd', 'ct_srv_src', 'ct_srv_dst', 'ct_dst_ltm', 'ct_src_ ltm',\n",
       "       'ct_src_dport_ltm', 'ct_dst_sport_ltm', 'ct_dst_src_ltm', 'attack_cat',\n",
       "       'Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "Cd0L_ETF4p_B"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>proto</th>\n",
       "      <th>state</th>\n",
       "      <th>dur</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>sttl</th>\n",
       "      <th>...</th>\n",
       "      <th>ct_ftp_cmd</th>\n",
       "      <th>ct_srv_src</th>\n",
       "      <th>ct_srv_dst</th>\n",
       "      <th>ct_dst_ltm</th>\n",
       "      <th>ct_src_ ltm</th>\n",
       "      <th>ct_src_dport_ltm</th>\n",
       "      <th>ct_dst_sport_ltm</th>\n",
       "      <th>ct_dst_src_ltm</th>\n",
       "      <th>attack_cat</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>7045</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>25</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.201886</td>\n",
       "      <td>37552</td>\n",
       "      <td>3380</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>9685</td>\n",
       "      <td>149.171.126.2</td>\n",
       "      <td>80</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>5.864748</td>\n",
       "      <td>19410</td>\n",
       "      <td>1087890</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.166.0.2</td>\n",
       "      <td>1421</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.166.0.2</td>\n",
       "      <td>21553</td>\n",
       "      <td>149.171.126.2</td>\n",
       "      <td>25</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.053948</td>\n",
       "      <td>37812</td>\n",
       "      <td>3380</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.166.0.8</td>\n",
       "      <td>45212</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>53</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>175.45.176.0</td>\n",
       "      <td>9910</td>\n",
       "      <td>149.171.126.10</td>\n",
       "      <td>80</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.230763</td>\n",
       "      <td>756</td>\n",
       "      <td>1356</td>\n",
       "      <td>62</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Exploits</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>53256</td>\n",
       "      <td>149.171.126.2</td>\n",
       "      <td>57469</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.291809</td>\n",
       "      <td>4862</td>\n",
       "      <td>82782</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>20197</td>\n",
       "      <td>149.171.126.6</td>\n",
       "      <td>111</td>\n",
       "      <td>udp</td>\n",
       "      <td>CON</td>\n",
       "      <td>0.004321</td>\n",
       "      <td>568</td>\n",
       "      <td>320</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>22425</td>\n",
       "      <td>149.171.126.6</td>\n",
       "      <td>65261</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.309355</td>\n",
       "      <td>4400</td>\n",
       "      <td>2976</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>59.166.0.7</td>\n",
       "      <td>19878</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>17834</td>\n",
       "      <td>tcp</td>\n",
       "      <td>FIN</td>\n",
       "      <td>0.019767</td>\n",
       "      <td>2646</td>\n",
       "      <td>25564</td>\n",
       "      <td>31</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>12</td>\n",
       "      <td>4</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 49 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            srcip  sport           dstip dsport proto state       dur  sbytes  \\\n",
       "0      59.166.0.9   7045   149.171.126.7     25   tcp   FIN  0.201886   37552   \n",
       "1      59.166.0.9   9685   149.171.126.2     80   tcp   FIN  5.864748   19410   \n",
       "2      59.166.0.2   1421   149.171.126.4     53   udp   CON  0.001391     146   \n",
       "3      59.166.0.2  21553   149.171.126.2     25   tcp   FIN  0.053948   37812   \n",
       "4      59.166.0.8  45212   149.171.126.4     53   udp   CON  0.000953     146   \n",
       "..            ...    ...             ...    ...   ...   ...       ...     ...   \n",
       "195  175.45.176.0   9910  149.171.126.10     80   tcp   FIN  0.230763     756   \n",
       "196    59.166.0.3  53256   149.171.126.2  57469   tcp   FIN  0.291809    4862   \n",
       "197    59.166.0.5  20197   149.171.126.6    111   udp   CON  0.004321     568   \n",
       "198    59.166.0.5  22425   149.171.126.6  65261   tcp   FIN  0.309355    4400   \n",
       "199    59.166.0.7  19878   149.171.126.4  17834   tcp   FIN  0.019767    2646   \n",
       "\n",
       "      dbytes  sttl  ...  ct_ftp_cmd  ct_srv_src  ct_srv_dst ct_dst_ltm  \\\n",
       "0       3380    31  ...                       2           2          7   \n",
       "1    1087890    31  ...                       3           1          4   \n",
       "2        178    31  ...                       3           5          2   \n",
       "3       3380    31  ...                       1           1          4   \n",
       "4        178    31  ...                       2           5          2   \n",
       "..       ...   ...  ...         ...         ...         ...        ...   \n",
       "195     1356    62  ...                       1           1          1   \n",
       "196    82782    31  ...                       4          10          1   \n",
       "197      320    31  ...                       6           8          4   \n",
       "198     2976    31  ...                       6           8          4   \n",
       "199    25564    31  ...                      12           4          3   \n",
       "\n",
       "     ct_src_ ltm  ct_src_dport_ltm  ct_dst_sport_ltm  ct_dst_src_ltm  \\\n",
       "0              4                 1                 1               3   \n",
       "1              4                 1                 1               1   \n",
       "2              7                 1                 1               4   \n",
       "3              7                 1                 1               3   \n",
       "4              1                 1                 1               2   \n",
       "..           ...               ...               ...             ...   \n",
       "195            1                 1                 1               1   \n",
       "196            2                 1                 1               1   \n",
       "197            4                 1                 1               3   \n",
       "198            4                 1                 1               3   \n",
       "199            4                 1                 1               2   \n",
       "\n",
       "     attack_cat  Label  \n",
       "0           NaN      0  \n",
       "1           NaN      0  \n",
       "2           NaN      0  \n",
       "3           NaN      0  \n",
       "4           NaN      0  \n",
       "..          ...    ...  \n",
       "195    Exploits      1  \n",
       "196         NaN      0  \n",
       "197         NaN      0  \n",
       "198         NaN      0  \n",
       "199         NaN      0  \n",
       "\n",
       "[200 rows x 49 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2[:200]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "mMKKWtauAN-z"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    351150\n",
       "1     88894\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "oaEigChD5lZ4"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'Analysis', nan, ' Fuzzers ', 'DoS', ' Shellcode ', 'Worms', 'Exploits', 'Generic', 'Backdoor', ' Reconnaissance '}\n",
      "Normal    351150\n",
      "DoS         4907\n",
      "Name: attack_cat, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# Print unique values in 'attack_cat' column\n",
    "print(set(data_2['attack_cat']))\n",
    "\n",
    "# Replace NaN values with 'Normal'\n",
    "data_2['attack_cat'].fillna('Normal', inplace=True)\n",
    "\n",
    "# Filter data_2 to keep only 'DoS' and 'Normal' rows\n",
    "data_2 = data_2[data_2['attack_cat'].isin(['DoS', 'Normal'])]\n",
    "\n",
    "# # Map 'DoS' to 1 (attack) and 'Normal' to 0 (benign) in data_2\n",
    "# data_2['label'] = data_2['attack_cat'].map({\n",
    "#     'Normal': 0,\n",
    "#     'DoS': 1\n",
    "# })\n",
    "\n",
    "# Verify the filtering\n",
    "print(data_2['attack_cat'].value_counts())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "Fh-rP7cxCz33"
   },
   "outputs": [],
   "source": [
    "# data_2= data_2[['srcip', 'sport', 'dstip', 'dsport', 'proto','dur',  'Spkts', 'Dpkts', 'sbytes',\n",
    "#        'dbytes', 'Label']]\n",
    "# protocol_mapping = {\n",
    "#     '3pc': 34, 'a/n': 155, 'aes-sp3-d': 108, 'any': 127, 'argus': 13, 'aris': 104, 'arp': 0, 'ax.25': 93, 'bbn-rcc': 10,\n",
    "#     'bna': 49, 'br-sat-mon': 76, 'cbt': 7, 'cftp': 62, 'chaos': 16, 'compaq-peer': 110, 'cphb': 73, 'cpnx': 72, 'crtp': 84,\n",
    "#     'crudp': 86, 'dcn': 0, 'ddp': 37, 'ddx': 116, 'dgp': 86, 'egp': 8, 'eigrp': 88, 'emcon': 14, 'encap': 98, 'etherip': 97,\n",
    "#     'fc': 133, 'fire': 125, 'ggp': 3, 'gmtp': 100, 'gre': 47, 'hmp': 20, 'i-nlsp': 52, 'iatp': 117, 'ib': 243, 'icmp': 1,\n",
    "#     'idpr': 35, 'idpr-cmtp': 38, 'idrp': 45, 'ifmp': 101, 'igmp': 2, 'igp': 9, 'il': 40, 'ip': 0, 'ipcomp': 108, 'ipcv': 71,\n",
    "#     'ipip': 4, 'iplt': 129, 'ipnip': 68, 'ippc': 67, 'ipv6': 41, 'ipv6-frag': 44, 'ipv6-no': 59, 'ipv6-opts': 60, 'ipv6-route': 43,\n",
    "#     'ipx-n-ip': 111, 'irtp': 28, 'isis': 124, 'iso-ip': 80, 'iso-tp4': 29, 'kryptolan': 65, 'l2tp': 115, 'larp': 91, 'leaf-1': 25,\n",
    "#     'leaf-2': 26, 'merit-inp': 32, 'mfe-nsp': 31, 'mhrp': 48, 'micp': 95, 'mobile': 55, 'mtp': 92, 'mux': 18, 'narp': 54, 'netblt': 30,\n",
    "#     'nsfnet-igp': 85, 'nvp': 11, 'ospf': 89, 'pgm': 113, 'pim': 103, 'pipe': 109, 'pnni': 102, 'pri-enc': 44, 'prm': 129, 'ptp': 123,\n",
    "#     'pup': 12, 'pvp': 75, 'qnx': 106, 'rdp': 27, 'rsvp': 46, 'rtp': 50, 'rvd': 66, 'sat-expak': 64, 'sat-mon': 69, 'sccopmce': 0,\n",
    "#     'scps': 53, 'sctp': 132, 'sdrp': 42, 'secure-vmtp': 82, 'sep': 33, 'skip': 57, 'sm': 122, 'smp': 121, 'snp': 109, 'sprite-rpc': 90,\n",
    "#     'sps': 129, 'srp': 126, 'st2': 5, 'stp': 118, 'sun-nd': 77, 'swipe': 53, 'tcf': 87, 'tcp': 6, 'tlsp': 56, 'tp++': 39, 'trunk-1': 23,\n",
    "#     'trunk-2': 24, 'ttp': 84, 'udp': 17, 'unas': 63, 'uti': 10, 'vines': 83, 'visa': 70, 'vmtp': 81, 'vrrp': 112, 'wb-expak': 79,\n",
    "#     'wb-mon': 78, 'wsn': 112, 'xnet': 15, 'xns-idp': 22, 'xtp': 36, 'zero': 255\n",
    "# }\n",
    "\n",
    "# # Apply the mapping\n",
    "# data_2['proto'] = data_2['proto'].map(protocol_mapping)\n",
    "\n",
    "# data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "NaFrbWLxfbm-"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>srcip</th>\n",
       "      <th>sport</th>\n",
       "      <th>dstip</th>\n",
       "      <th>dsport</th>\n",
       "      <th>dur</th>\n",
       "      <th>Spkts</th>\n",
       "      <th>Dpkts</th>\n",
       "      <th>sbytes</th>\n",
       "      <th>dbytes</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>7045</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>25</td>\n",
       "      <td>0.201886</td>\n",
       "      <td>52</td>\n",
       "      <td>42</td>\n",
       "      <td>37552</td>\n",
       "      <td>3380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>9685</td>\n",
       "      <td>149.171.126.2</td>\n",
       "      <td>80</td>\n",
       "      <td>5.864748</td>\n",
       "      <td>364</td>\n",
       "      <td>746</td>\n",
       "      <td>19410</td>\n",
       "      <td>1087890</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>59.166.0.2</td>\n",
       "      <td>1421</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.001391</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>59.166.0.2</td>\n",
       "      <td>21553</td>\n",
       "      <td>149.171.126.2</td>\n",
       "      <td>25</td>\n",
       "      <td>0.053948</td>\n",
       "      <td>54</td>\n",
       "      <td>42</td>\n",
       "      <td>37812</td>\n",
       "      <td>3380</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59.166.0.8</td>\n",
       "      <td>45212</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>53</td>\n",
       "      <td>0.000953</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>146</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440038</th>\n",
       "      <td>59.166.0.1</td>\n",
       "      <td>38606</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>80</td>\n",
       "      <td>0.564998</td>\n",
       "      <td>262</td>\n",
       "      <td>526</td>\n",
       "      <td>14106</td>\n",
       "      <td>772406</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440039</th>\n",
       "      <td>59.166.0.5</td>\n",
       "      <td>33094</td>\n",
       "      <td>149.171.126.7</td>\n",
       "      <td>43433</td>\n",
       "      <td>0.087306</td>\n",
       "      <td>6</td>\n",
       "      <td>8</td>\n",
       "      <td>320</td>\n",
       "      <td>1828</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440040</th>\n",
       "      <td>59.166.0.7</td>\n",
       "      <td>20848</td>\n",
       "      <td>149.171.126.4</td>\n",
       "      <td>21</td>\n",
       "      <td>0.365058</td>\n",
       "      <td>8</td>\n",
       "      <td>6</td>\n",
       "      <td>456</td>\n",
       "      <td>346</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440041</th>\n",
       "      <td>59.166.0.3</td>\n",
       "      <td>21511</td>\n",
       "      <td>149.171.126.9</td>\n",
       "      <td>21</td>\n",
       "      <td>6.335154</td>\n",
       "      <td>32</td>\n",
       "      <td>30</td>\n",
       "      <td>1802</td>\n",
       "      <td>2088</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440042</th>\n",
       "      <td>59.166.0.9</td>\n",
       "      <td>35433</td>\n",
       "      <td>149.171.126.0</td>\n",
       "      <td>80</td>\n",
       "      <td>2.200934</td>\n",
       "      <td>58</td>\n",
       "      <td>116</td>\n",
       "      <td>3498</td>\n",
       "      <td>166054</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>356057 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             srcip  sport          dstip dsport       dur  Spkts  Dpkts  \\\n",
       "0       59.166.0.9   7045  149.171.126.7     25  0.201886     52     42   \n",
       "1       59.166.0.9   9685  149.171.126.2     80  5.864748    364    746   \n",
       "2       59.166.0.2   1421  149.171.126.4     53  0.001391      2      2   \n",
       "3       59.166.0.2  21553  149.171.126.2     25  0.053948     54     42   \n",
       "4       59.166.0.8  45212  149.171.126.4     53  0.000953      2      2   \n",
       "...            ...    ...            ...    ...       ...    ...    ...   \n",
       "440038  59.166.0.1  38606  149.171.126.9     80  0.564998    262    526   \n",
       "440039  59.166.0.5  33094  149.171.126.7  43433  0.087306      6      8   \n",
       "440040  59.166.0.7  20848  149.171.126.4     21  0.365058      8      6   \n",
       "440041  59.166.0.3  21511  149.171.126.9     21  6.335154     32     30   \n",
       "440042  59.166.0.9  35433  149.171.126.0     80  2.200934     58    116   \n",
       "\n",
       "        sbytes   dbytes  Label  \n",
       "0        37552     3380      0  \n",
       "1        19410  1087890      0  \n",
       "2          146      178      0  \n",
       "3        37812     3380      0  \n",
       "4          146      178      0  \n",
       "...        ...      ...    ...  \n",
       "440038   14106   772406      0  \n",
       "440039     320     1828      0  \n",
       "440040     456      346      0  \n",
       "440041    1802     2088      0  \n",
       "440042    3498   166054      0  \n",
       "\n",
       "[356057 rows x 10 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2= data_2[['srcip', 'sport', 'dstip', 'dsport','dur',  'Spkts', 'Dpkts', 'sbytes',\n",
    "       'dbytes', 'Label']]\n",
    "data_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "id": "gcYCffhU32nC"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    351150\n",
       "1      4907\n",
       "Name: Label, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2['Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "ubkGgDbgO_j5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels in the balanced data: 2\n",
      "Frequency of each unique label in the balanced data:\n",
      "0    15000\n",
      "1    15000\n",
      "Name: Label, dtype: int64\n",
      "Frequency of each unique label in the original data:\n",
      "0    351150\n",
      "1      4907\n",
      "Name: Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Set the desired number of majority class samples\n",
    "num_majority_samples = 15000  # Adjust this number as needed\n",
    "\n",
    "# Get the minority class label\n",
    "minority_class = data_2['Label'].value_counts().idxmin()\n",
    "\n",
    "# Separate majority and minority class samples\n",
    "majority_samples = data_2[data_2['Label'] != minority_class]\n",
    "minority_samples = data_2[data_2['Label'] == minority_class]\n",
    "\n",
    "# Sample the majority class samples\n",
    "majority_samples_sampled = majority_samples.sample(num_majority_samples, random_state=42)\n",
    "\n",
    "# Upsample the minority class samples\n",
    "minority_samples_upsampled = resample(\n",
    "    minority_samples,\n",
    "    replace=True,  # Sample with replacement\n",
    "    n_samples=num_majority_samples,  # Match the number of majority samples\n",
    "    random_state=42  # Reproducible results\n",
    ")\n",
    "\n",
    "# Combine the sampled majority class samples and upsampled minority class samples\n",
    "balanced_data_2 = pd.concat([majority_samples_sampled, minority_samples_upsampled], axis=0)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_data_2 = balanced_data_2.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print some information about the balanced dataset\n",
    "balanced_data.head()\n",
    "num_unique_labels = balanced_data_2['Label'].nunique()\n",
    "print(\"Number of unique labels in the balanced data:\", num_unique_labels)\n",
    "label_frequency = balanced_data_2['Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the balanced data:\")\n",
    "print(label_frequency)\n",
    "label_frequency_data = data_2['Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the original data:\")\n",
    "print(label_frequency_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "OY28Y2JfO__L"
   },
   "outputs": [],
   "source": [
    "data_2 =  balanced_data_2.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xOuY2pwhMc6G",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Dataset3 Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "mhVnzDNiMgO3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Flow ID', ' Source IP', ' Source Port', ' Destination IP',\n",
       "       ' Destination Port', ' Protocol', ' Timestamp', ' Flow Duration',\n",
       "       ' Total Fwd Packets', ' Total Backward Packets',\n",
       "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
       "       ' Fwd Packet Length Max', ' Fwd Packet Length Min',\n",
       "       ' Fwd Packet Length Mean', ' Fwd Packet Length Std',\n",
       "       'Bwd Packet Length Max', ' Bwd Packet Length Min',\n",
       "       ' Bwd Packet Length Mean', ' Bwd Packet Length Std', 'Flow Bytes/s',\n",
       "       ' Flow Packets/s', ' Flow IAT Mean', ' Flow IAT Std', ' Flow IAT Max',\n",
       "       ' Flow IAT Min', 'Fwd IAT Total', ' Fwd IAT Mean', ' Fwd IAT Std',\n",
       "       ' Fwd IAT Max', ' Fwd IAT Min', 'Bwd IAT Total', ' Bwd IAT Mean',\n",
       "       ' Bwd IAT Std', ' Bwd IAT Max', ' Bwd IAT Min', 'Fwd PSH Flags',\n",
       "       ' Bwd PSH Flags', ' Fwd URG Flags', ' Bwd URG Flags',\n",
       "       ' Fwd Header Length', ' Bwd Header Length', 'Fwd Packets/s',\n",
       "       ' Bwd Packets/s', ' Min Packet Length', ' Max Packet Length',\n",
       "       ' Packet Length Mean', ' Packet Length Std', ' Packet Length Variance',\n",
       "       'FIN Flag Count', ' SYN Flag Count', ' RST Flag Count',\n",
       "       ' PSH Flag Count', ' ACK Flag Count', ' URG Flag Count',\n",
       "       ' CWE Flag Count', ' ECE Flag Count', ' Down/Up Ratio',\n",
       "       ' Average Packet Size', ' Avg Fwd Segment Size',\n",
       "       ' Avg Bwd Segment Size', ' Fwd Header Length.1', 'Fwd Avg Bytes/Bulk',\n",
       "       ' Fwd Avg Packets/Bulk', ' Fwd Avg Bulk Rate', ' Bwd Avg Bytes/Bulk',\n",
       "       ' Bwd Avg Packets/Bulk', 'Bwd Avg Bulk Rate', 'Subflow Fwd Packets',\n",
       "       ' Subflow Fwd Bytes', ' Subflow Bwd Packets', ' Subflow Bwd Bytes',\n",
       "       'Init_Win_bytes_forward', ' Init_Win_bytes_backward',\n",
       "       ' act_data_pkt_fwd', ' min_seg_size_forward', 'Active Mean',\n",
       "       ' Active Std', ' Active Max', ' Active Min', 'Idle Mean', ' Idle Std',\n",
       "       ' Idle Max', ' Idle Min', ' Label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "Ny_qGk3iP2nF"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Source IP</th>\n",
       "      <th>Source Port</th>\n",
       "      <th>Destination IP</th>\n",
       "      <th>Destination Port</th>\n",
       "      <th>Flow Duration</th>\n",
       "      <th>Total Fwd Packets</th>\n",
       "      <th>Total Backward Packets</th>\n",
       "      <th>Total Length of Fwd Packets</th>\n",
       "      <th>Total Length of Bwd Packets</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>104.16.207.165</td>\n",
       "      <td>443</td>\n",
       "      <td>192.168.10.5</td>\n",
       "      <td>54865</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>104.16.28.216</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.5</td>\n",
       "      <td>55054</td>\n",
       "      <td>109</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>104.16.28.216</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.5</td>\n",
       "      <td>55055</td>\n",
       "      <td>52</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>104.17.241.25</td>\n",
       "      <td>443</td>\n",
       "      <td>192.168.10.16</td>\n",
       "      <td>46236</td>\n",
       "      <td>34</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.19.196.102</td>\n",
       "      <td>443</td>\n",
       "      <td>192.168.10.5</td>\n",
       "      <td>54863</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225740</th>\n",
       "      <td>72.21.91.29</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.15</td>\n",
       "      <td>61374</td>\n",
       "      <td>61</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225741</th>\n",
       "      <td>72.21.91.29</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.15</td>\n",
       "      <td>61378</td>\n",
       "      <td>72</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225742</th>\n",
       "      <td>72.21.91.29</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.15</td>\n",
       "      <td>61375</td>\n",
       "      <td>75</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225743</th>\n",
       "      <td>8.41.222.187</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.15</td>\n",
       "      <td>61323</td>\n",
       "      <td>48</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>225744</th>\n",
       "      <td>8.43.72.21</td>\n",
       "      <td>80</td>\n",
       "      <td>192.168.10.15</td>\n",
       "      <td>61326</td>\n",
       "      <td>68</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6</td>\n",
       "      <td>BENIGN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>225745 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "             Source IP   Source Port  Destination IP   Destination Port  \\\n",
       "0       104.16.207.165           443    192.168.10.5              54865   \n",
       "1        104.16.28.216            80    192.168.10.5              55054   \n",
       "2        104.16.28.216            80    192.168.10.5              55055   \n",
       "3        104.17.241.25           443   192.168.10.16              46236   \n",
       "4       104.19.196.102           443    192.168.10.5              54863   \n",
       "...                ...           ...             ...                ...   \n",
       "225740     72.21.91.29            80   192.168.10.15              61374   \n",
       "225741     72.21.91.29            80   192.168.10.15              61378   \n",
       "225742     72.21.91.29            80   192.168.10.15              61375   \n",
       "225743    8.41.222.187            80   192.168.10.15              61323   \n",
       "225744      8.43.72.21            80   192.168.10.15              61326   \n",
       "\n",
       "         Flow Duration   Total Fwd Packets   Total Backward Packets  \\\n",
       "0                    3                   2                        0   \n",
       "1                  109                   1                        1   \n",
       "2                   52                   1                        1   \n",
       "3                   34                   1                        1   \n",
       "4                    3                   2                        0   \n",
       "...                ...                 ...                      ...   \n",
       "225740              61                   1                        1   \n",
       "225741              72                   1                        1   \n",
       "225742              75                   1                        1   \n",
       "225743              48                   2                        0   \n",
       "225744              68                   1                        1   \n",
       "\n",
       "        Total Length of Fwd Packets   Total Length of Bwd Packets   Label  \n",
       "0                                12                             0  BENIGN  \n",
       "1                                 6                             6  BENIGN  \n",
       "2                                 6                             6  BENIGN  \n",
       "3                                 6                             6  BENIGN  \n",
       "4                                12                             0  BENIGN  \n",
       "...                             ...                           ...     ...  \n",
       "225740                            6                             6  BENIGN  \n",
       "225741                            6                             6  BENIGN  \n",
       "225742                            6                             6  BENIGN  \n",
       "225743                           12                             0  BENIGN  \n",
       "225744                            6                             6  BENIGN  \n",
       "\n",
       "[225745 rows x 10 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_3 = data_3[[' Source IP', ' Source Port', ' Destination IP',\n",
    "#        ' Destination Port', ' Protocol', ' Flow Duration',\n",
    "#        ' Total Fwd Packets', ' Total Backward Packets',\n",
    "      #  'Total Length of Fwd Packets', ' Total Length of Bwd Packets',' Label']]\n",
    "data_3 = data_3[[' Source IP', ' Source Port', ' Destination IP',\n",
    "       ' Destination Port',' Flow Duration',\n",
    "       ' Total Fwd Packets', ' Total Backward Packets',\n",
    "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets',' Label']]\n",
    "\n",
    "data_3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "gt5Y5TPAQuKg"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'BENIGN', 'DDoS'}\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0         0\n",
       "1         0\n",
       "2         0\n",
       "3         0\n",
       "4         0\n",
       "         ..\n",
       "225740    0\n",
       "225741    0\n",
       "225742    0\n",
       "225743    0\n",
       "225744    0\n",
       "Name:  Label, Length: 225745, dtype: int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(set(data_3[' Label']))\n",
    "\n",
    "data_3[' Label'].value_counts()\n",
    "# Map labels in data_1 to binary\n",
    "data_3[' Label'] = data_3[' Label'].map({\n",
    "    'BENIGN': 0,\n",
    "    'DDoS': 1})\n",
    "\n",
    "data_3[' Label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "Xgu8cObb51PX"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    128027\n",
       "0     97718\n",
       "Name:  Label, dtype: int64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3[' Label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "AdcxcB6yifiO"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of unique labels in the balanced data: 2\n",
      "Frequency of each unique label in the balanced data:\n",
      "1    15000\n",
      "0    15000\n",
      "Name:  Label, dtype: int64\n",
      "Frequency of each unique label in the original data:\n",
      "1    128027\n",
      "0     97718\n",
      "Name:  Label, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.utils import resample\n",
    "\n",
    "# Set the desired number of majority class samples\n",
    "num_majority_samples = 15000  # Adjust this number as needed\n",
    "\n",
    "# Get the minority class label\n",
    "minority_class = data_3[' Label'].value_counts().idxmin()\n",
    "\n",
    "# Separate majority and minority class samples\n",
    "majority_samples = data_3[data_3[' Label'] != minority_class]\n",
    "minority_samples = data_3[data_3[' Label'] == minority_class]\n",
    "\n",
    "# Sample the majority class samples\n",
    "majority_samples_sampled = majority_samples.sample(num_majority_samples, random_state=42)\n",
    "\n",
    "# Upsample the minority class samples\n",
    "minority_samples_upsampled = resample(\n",
    "    minority_samples,\n",
    "    replace=True,  # Sample with replacement\n",
    "    n_samples=num_majority_samples,  # Match the number of majority samples\n",
    "    random_state=42  # Reproducible results\n",
    ")\n",
    "\n",
    "# Combine the sampled majority class samples and upsampled minority class samples\n",
    "balanced_data_3 = pd.concat([majority_samples_sampled, minority_samples_upsampled], axis=0)\n",
    "\n",
    "# Shuffle the balanced dataset\n",
    "balanced_data_3 = balanced_data_3.sample(frac=1, random_state=42).reset_index(drop=True)\n",
    "\n",
    "# Print some information about the balanced dataset\n",
    "balanced_data.head()\n",
    "num_unique_labels = balanced_data_3[' Label'].nunique()\n",
    "print(\"Number of unique labels in the balanced data:\", num_unique_labels)\n",
    "label_frequency = balanced_data_3[' Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the balanced data:\")\n",
    "print(label_frequency)\n",
    "label_frequency_data = data_3[' Label'].value_counts()\n",
    "print(\"Frequency of each unique label in the original data:\")\n",
    "print(label_frequency_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "s4TpOjXpj5xd"
   },
   "outputs": [],
   "source": [
    "data_3 = balanced_data_3.copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SNnplKV5MmZi",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Standardizing Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "cxDhrs85RIch"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index([' Source IP', ' Source Port', ' Destination IP', ' Destination Port',\n",
       "        ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
       "        'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
       "        ' Label'],\n",
       "       dtype='object'),\n",
       " Index(['srcip', 'sport', 'dstip', 'dsport', 'dur', 'Spkts', 'Dpkts', 'sbytes',\n",
       "        'dbytes', 'Label'],\n",
       "       dtype='object'),\n",
       " Index([' Source IP', ' Source Port', ' Destination IP', ' Destination Port',\n",
       "        ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
       "        'Total Length of Fwd Packets', ' Total Length of Bwd Packets',\n",
       "        ' Label'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns,data_2.columns,data_3.columns,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "id": "wIyTViFfTWtZ"
   },
   "outputs": [],
   "source": [
    "# Standardize column names\n",
    "rename_dict = {\n",
    "    ' Source IP': 'src_ip', ' Source Port': 'src_port', ' Destination IP': 'dst_ip', ' Destination Port': 'dst_port',\n",
    "    ' Protocol': 'protocol', ' Flow Duration': 'flow_duration', ' Total Fwd Packets': 'total_fwd_packets',\n",
    "    ' Total Backward Packets': 'total_bwd_packets', 'Total Length of Fwd Packets': 'total_len_fwd_packets',\n",
    "    ' Total Length of Bwd Packets': 'total_len_bwd_packets', ' Label': 'label',\n",
    "\n",
    "    'srcip': 'src_ip', 'sport': 'src_port', 'dstip': 'dst_ip', 'dsport': 'dst_port',\n",
    "    'proto': 'protocol', 'dur': 'flow_duration', 'Spkts': 'total_fwd_packets', 'Dpkts': 'total_bwd_packets',\n",
    "    'sbytes': 'total_len_fwd_packets', 'dbytes': 'total_len_bwd_packets', 'Label': 'label'\n",
    "}\n",
    "\n",
    "data.rename(columns=rename_dict, inplace=True)\n",
    "data_2.rename(columns=rename_dict, inplace=True)\n",
    "data_3.rename(columns=rename_dict, inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "id": "cA_6Oi0HTfiR"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['src_ip', 'src_port', 'dst_ip', 'dst_port', 'flow_duration',\n",
       "        'total_fwd_packets', 'total_bwd_packets', 'total_len_fwd_packets',\n",
       "        'total_len_bwd_packets', 'label'],\n",
       "       dtype='object'),\n",
       " Index(['src_ip', 'src_port', 'dst_ip', 'dst_port', 'flow_duration',\n",
       "        'total_fwd_packets', 'total_bwd_packets', 'total_len_fwd_packets',\n",
       "        'total_len_bwd_packets', 'label'],\n",
       "       dtype='object'),\n",
       " Index(['src_ip', 'src_port', 'dst_ip', 'dst_port', 'flow_duration',\n",
       "        'total_fwd_packets', 'total_bwd_packets', 'total_len_fwd_packets',\n",
       "        'total_len_bwd_packets', 'label'],\n",
       "       dtype='object'))"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns,data_2.columns,data_3.columns,"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "je4r0x97SWz8"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_MGSeFEM38Z",
    "jp-MarkdownHeadingCollapsed": true,
    "tags": []
   },
   "source": [
    "## Preparing Data for Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "id": "7iiMZNqDiAZ6"
   },
   "outputs": [],
   "source": [
    "# # Encode categorical features (e.g., IP addresses)\n",
    "# encoder = LabelEncoder()\n",
    "# data['src_ip'] = encoder.fit_transform(data['src_ip'])\n",
    "# data['dst_ip'] = encoder.fit_transform(data['dst_ip'])\n",
    "# # data['protocol'] = encoder.fit_transform(data['protocol'])\n",
    "# data['label'] = encoder.fit_transform(data['label'])\n",
    "# data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "id": "41ONtYl-Xrmi"
   },
   "outputs": [],
   "source": [
    "# # Encode categorical features (e.g., IP addresses)\n",
    "# encoder1 = LabelEncoder()\n",
    "# data_2['src_ip'] = encoder1.fit_transform(data_2['src_ip'])\n",
    "# data_2['dst_ip'] = encoder1.fit_transform(data_2['dst_ip'])\n",
    "# # data['protocol'] = encoder.fit_transform(data_2['protocol'])\n",
    "# data_2['label'] = encoder1.fit_transform(data_2['label'])\n",
    "# data_2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "04Wcuy1jX6bH"
   },
   "outputs": [],
   "source": [
    "# # Encode categorical features (e.g., IP addresses)\n",
    "# encoder3 = LabelEncoder()\n",
    "# data_3['src_ip'] = encoder3.fit_transform(data_3['src_ip'])\n",
    "# data_3['dst_ip'] = encoder3.fit_transform(data_3['dst_ip'])\n",
    "# # data_3['protocol'] = encoder.fit_transform(data_3['protocol'])\n",
    "# data_3['label'] = encoder3.fit_transform(data_3['label'])\n",
    "# data_3.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "id": "ErMV4UYTYvGj"
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>total_fwd_packets</th>\n",
       "      <th>total_bwd_packets</th>\n",
       "      <th>total_len_fwd_packets</th>\n",
       "      <th>total_len_bwd_packets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>988</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>12698</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>192.168.50.8</td>\n",
       "      <td>59610</td>\n",
       "      <td>172.217.9.230</td>\n",
       "      <td>443</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>192.168.50.6</td>\n",
       "      <td>63363</td>\n",
       "      <td>4.2.2.4</td>\n",
       "      <td>53</td>\n",
       "      <td>20587.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>92.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>162.248.19.151</td>\n",
       "      <td>443</td>\n",
       "      <td>192.168.50.8</td>\n",
       "      <td>59846</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>172.16.0.5</td>\n",
       "      <td>833</td>\n",
       "      <td>192.168.50.4</td>\n",
       "      <td>15291</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89995</th>\n",
       "      <td>192.168.10.14</td>\n",
       "      <td>57704</td>\n",
       "      <td>152.195.12.73</td>\n",
       "      <td>443</td>\n",
       "      <td>62465310.0</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>104.0</td>\n",
       "      <td>193.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89996</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>40765</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80</td>\n",
       "      <td>731478.0</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>11601.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89997</th>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>51227</td>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80</td>\n",
       "      <td>7680856.0</td>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89998</th>\n",
       "      <td>192.168.10.14</td>\n",
       "      <td>54210</td>\n",
       "      <td>192.168.10.3</td>\n",
       "      <td>53</td>\n",
       "      <td>143915.0</td>\n",
       "      <td>4</td>\n",
       "      <td>2</td>\n",
       "      <td>124.0</td>\n",
       "      <td>222.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89999</th>\n",
       "      <td>192.168.10.50</td>\n",
       "      <td>80</td>\n",
       "      <td>172.16.0.1</td>\n",
       "      <td>40326</td>\n",
       "      <td>1243119.0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>6.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>90000 rows × 10 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "               src_ip  src_port         dst_ip dst_port  flow_duration  \\\n",
       "0          172.16.0.5       988   192.168.50.4    12698            1.0   \n",
       "1        192.168.50.8     59610  172.217.9.230      443         1452.0   \n",
       "2        192.168.50.6     63363        4.2.2.4       53        20587.0   \n",
       "3      162.248.19.151       443   192.168.50.8    59846            4.0   \n",
       "4          172.16.0.5       833   192.168.50.4    15291            0.0   \n",
       "...               ...       ...            ...      ...            ...   \n",
       "89995   192.168.10.14     57704  152.195.12.73      443     62465310.0   \n",
       "89996      172.16.0.1     40765  192.168.10.50       80       731478.0   \n",
       "89997      172.16.0.1     51227  192.168.10.50       80      7680856.0   \n",
       "89998   192.168.10.14     54210   192.168.10.3       53       143915.0   \n",
       "89999   192.168.10.50        80     172.16.0.1    40326      1243119.0   \n",
       "\n",
       "       total_fwd_packets  total_bwd_packets  total_len_fwd_packets  \\\n",
       "0                      2                  0                  458.0   \n",
       "1                      4                  0                  129.0   \n",
       "2                      2                  2                   92.0   \n",
       "3                      3                  0                   18.0   \n",
       "4                      2                  0                  458.0   \n",
       "...                  ...                ...                    ...   \n",
       "89995                  4                  5                  104.0   \n",
       "89996                  3                  5                   26.0   \n",
       "89997                  5                  0                   30.0   \n",
       "89998                  4                  2                  124.0   \n",
       "89999                  1                  6                    6.0   \n",
       "\n",
       "       total_len_bwd_packets  label  \n",
       "0                        0.0      1  \n",
       "1                        0.0      0  \n",
       "2                      170.0      0  \n",
       "3                        0.0      0  \n",
       "4                        0.0      1  \n",
       "...                      ...    ...  \n",
       "89995                  193.0      0  \n",
       "89996                11601.0      1  \n",
       "89997                    0.0      1  \n",
       "89998                  222.0      0  \n",
       "89999                   36.0      0  \n",
       "\n",
       "[90000 rows x 10 columns]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Handle missing values\n",
    "data.fillna(0, inplace=True)\n",
    "data_2.fillna(0, inplace=True)\n",
    "data_3.fillna(0, inplace=True)\n",
    "\n",
    "# Combine the datasets vertically\n",
    "combined_data = pd.concat([data,data_2, data_3], ignore_index=True)\n",
    "combined_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "bUo4LpLQZDjk"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    45000\n",
       "0    45000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "A9fPtaTYX_Iq"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['src_ip', 'src_port', 'dst_ip', 'dst_port', 'flow_duration',\n",
       "       'total_fwd_packets', 'total_bwd_packets', 'total_len_fwd_packets',\n",
       "       'total_len_bwd_packets', 'label'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "id": "aBTOHf3GVvlE"
   },
   "outputs": [],
   "source": [
    "# # Encode categorical features (e.g., IP addresses)\n",
    "# encoder = LabelEncoder()\n",
    "# combined_data['src_ip'] = encoder.fit_transform(combined_data['src_ip'])\n",
    "# combined_data['dst_ip'] = encoder.fit_transform(combined_data['dst_ip'])\n",
    "# # combined_data['protocol'] = encoder.fit_transform(combined_data['protocol'])\n",
    "# combined_data['label'] = encoder.fit_transform(combined_data['label'])\n",
    "# combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "id": "_SMk4Y1kjcge"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Encoders saved successfully!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>src_ip</th>\n",
       "      <th>src_port</th>\n",
       "      <th>dst_ip</th>\n",
       "      <th>dst_port</th>\n",
       "      <th>flow_duration</th>\n",
       "      <th>total_fwd_packets</th>\n",
       "      <th>total_bwd_packets</th>\n",
       "      <th>total_len_fwd_packets</th>\n",
       "      <th>total_len_bwd_packets</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>192</td>\n",
       "      <td>494</td>\n",
       "      <td>560</td>\n",
       "      <td>816</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>373</td>\n",
       "      <td>22889</td>\n",
       "      <td>440</td>\n",
       "      <td>10741</td>\n",
       "      <td>1452.0</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>129.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>371</td>\n",
       "      <td>25859</td>\n",
       "      <td>944</td>\n",
       "      <td>13818</td>\n",
       "      <td>20587.0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>92.0</td>\n",
       "      <td>170.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>187</td>\n",
       "      <td>14</td>\n",
       "      <td>563</td>\n",
       "      <td>17289</td>\n",
       "      <td>4.0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>192</td>\n",
       "      <td>339</td>\n",
       "      <td>560</td>\n",
       "      <td>1607</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>458.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   src_ip  src_port  dst_ip  dst_port  flow_duration  total_fwd_packets  \\\n",
       "0     192       494     560       816            1.0                  2   \n",
       "1     373     22889     440     10741         1452.0                  4   \n",
       "2     371     25859     944     13818        20587.0                  2   \n",
       "3     187        14     563     17289            4.0                  3   \n",
       "4     192       339     560      1607            0.0                  2   \n",
       "\n",
       "   total_bwd_packets  total_len_fwd_packets  total_len_bwd_packets  label  \n",
       "0                  0                  458.0                    0.0      1  \n",
       "1                  0                  129.0                    0.0      0  \n",
       "2                  2                   92.0                  170.0      0  \n",
       "3                  0                   18.0                    0.0      0  \n",
       "4                  0                  458.0                    0.0      1  "
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import pickle\n",
    "\n",
    "# Create separate LabelEncoders for each categorical feature\n",
    "encoder_src_ip = LabelEncoder()\n",
    "encoder_dst_ip = LabelEncoder()\n",
    "encoder_src_port = LabelEncoder()\n",
    "encoder_dst_port = LabelEncoder()\n",
    "\n",
    "encoder_label = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical features\n",
    "combined_data['src_ip'] = encoder_src_ip.fit_transform(combined_data['src_ip'])\n",
    "combined_data['dst_ip'] = encoder_dst_ip.fit_transform(combined_data['dst_ip'])\n",
    "combined_data['src_port'] = encoder_src_port.fit_transform(combined_data['src_port'])\n",
    "combined_data['dst_port'] = encoder_dst_port.fit_transform(combined_data['dst_port'].astype(str))\n",
    "\n",
    "combined_data['label'] = encoder_label.fit_transform(combined_data['label'])\n",
    "\n",
    "# Save the encoders\n",
    "with open('encoder_src_ip.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder_src_ip, f)\n",
    "\n",
    "with open('encoder_dst_ip.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder_dst_ip, f)\n",
    "# Save the encoders\n",
    "with open('encoder_src_port.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder_src_port, f)\n",
    "\n",
    "with open('encoder_dst_port.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder_dst_port, f)\n",
    "\n",
    "with open('encoder_label.pkl', 'wb') as f:\n",
    "    pickle.dump(encoder_label, f)\n",
    "\n",
    "print(\"Encoders saved successfully!\")\n",
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "s26T5AoCs-FD"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 90000 entries, 0 to 89999\n",
      "Data columns (total 10 columns):\n",
      " #   Column                 Non-Null Count  Dtype  \n",
      "---  ------                 --------------  -----  \n",
      " 0   src_ip                 90000 non-null  int64  \n",
      " 1   src_port               90000 non-null  int64  \n",
      " 2   dst_ip                 90000 non-null  int64  \n",
      " 3   dst_port               90000 non-null  int64  \n",
      " 4   flow_duration          90000 non-null  float64\n",
      " 5   total_fwd_packets      90000 non-null  int64  \n",
      " 6   total_bwd_packets      90000 non-null  int64  \n",
      " 7   total_len_fwd_packets  90000 non-null  float64\n",
      " 8   total_len_bwd_packets  90000 non-null  float64\n",
      " 9   label                  90000 non-null  int64  \n",
      "dtypes: float64(3), int64(7)\n",
      "memory usage: 6.9 MB\n"
     ]
    }
   ],
   "source": [
    "combined_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "id": "DKXfXqVKm83F"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    45000\n",
       "0    45000\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "combined_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "id": "hly-X2lxty9k"
   },
   "outputs": [],
   "source": [
    "# Split the data into train and test sets\n",
    "\n",
    "X = combined_data.drop('label', axis=1)\n",
    "y = combined_data['label']\n",
    "\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2,stratify = y, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "id": "khLWdYqZ78lu"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['src_ip', 'src_port', 'dst_ip', 'dst_port', 'flow_duration',\n",
       "       'total_fwd_packets', 'total_bwd_packets', 'total_len_fwd_packets',\n",
       "       'total_len_bwd_packets'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "id": "X9Ssmjv1t5_E"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.isnull().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "id": "7DarY50-t9TA"
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Function to check for data issues\n",
    "def check_data_issues(data):\n",
    "    if data.isnull().values.any():\n",
    "        print(\"There are NaN values in the dataset.\")\n",
    "    else:\n",
    "        print(\"No NaN values found in the dataset.\")\n",
    "\n",
    "    if np.isinf(data).values.any():\n",
    "        print(\"There are infinite values in the dataset.\")\n",
    "    else:\n",
    "        print(\"No infinite values found in the dataset.\")\n",
    "\n",
    "    max_value = data.max().max()\n",
    "    if max_value > np.finfo(np.float64).max:\n",
    "        print(f\"There are values too large for dtype('float64') in the dataset. Max value: {max_value}\")\n",
    "    else:\n",
    "        print(\"No values too large for dtype('float64') found in the dataset.\")\n",
    "\n",
    "    min_value = data.min().min()\n",
    "    if min_value < np.finfo(np.float64).min:\n",
    "        print(f\"There are values too small for dtype('float64') in the dataset. Min value: {min_value}\")\n",
    "    else:\n",
    "        print(\"No values too small for dtype('float64') found in the dataset.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "id": "siqmSmeV615R"
   },
   "outputs": [],
   "source": [
    "# Separate numeric and categorical columns\n",
    "numeric_columns = X_train.select_dtypes(include=[np.number]).columns\n",
    "categorical_columns = X_train.select_dtypes(exclude=[np.number]).columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "id": "WvnfqNTI63x0"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Index(['src_ip', 'src_port', 'dst_ip', 'dst_port', 'flow_duration',\n",
       "        'total_fwd_packets', 'total_bwd_packets', 'total_len_fwd_packets',\n",
       "        'total_len_bwd_packets'],\n",
       "       dtype='object'),\n",
       " Index([], dtype='object'))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Separate numeric and categorical columns\n",
    "numeric_columns,categorical_columns\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "id": "VXKEKw8guSJj"
   },
   "outputs": [],
   "source": [
    "# Replace infinity values with NaN\n",
    "X_train.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "X_test.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "\n",
    "# Impute NaN values with the mean of the corresponding column\n",
    "from sklearn.impute import SimpleImputer\n",
    "\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_train = imputer.fit_transform(X_train)\n",
    "X_test = imputer.transform(X_test)\n",
    "\n",
    "# Now, standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "id": "PfnrV4BCt9nH"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking X_train:\n",
      "No NaN values found in the dataset.\n",
      "No infinite values found in the dataset.\n",
      "No values too large for dtype('float64') found in the dataset.\n",
      "No values too small for dtype('float64') found in the dataset.\n",
      "\n",
      "Checking X_test:\n",
      "No NaN values found in the dataset.\n",
      "No infinite values found in the dataset.\n",
      "No values too large for dtype('float64') found in the dataset.\n",
      "No values too small for dtype('float64') found in the dataset.\n"
     ]
    }
   ],
   "source": [
    "X_train = pd.DataFrame(X_train, columns=X.columns)\n",
    "X_test = pd.DataFrame(X_test, columns=X.columns)\n",
    "\n",
    "\n",
    "# Check the training and testing datasets for issues\n",
    "print(\"Checking X_train:\")\n",
    "check_data_issues(X_train)\n",
    "print(\"\\nChecking X_test:\")\n",
    "check_data_issues(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "id": "rW2E-Hyy6RhG"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['src_ip', 'src_port', 'dst_ip', 'dst_port', 'flow_duration',\n",
       "       'total_fwd_packets', 'total_bwd_packets', 'total_len_fwd_packets',\n",
       "       'total_len_bwd_packets'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.columns\n",
    "column_names =X_train.columns\n",
    "column_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "id": "BXJO_fNc41Lv"
   },
   "outputs": [],
   "source": [
    "# type(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "id": "zlpIcXMOvUX6"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(72000, 9)"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "XTWVrQXmgA2r"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape (72000, 9)\n",
      "Logistic Regression:\n",
      "Accuracy: 0.9424444444444444\n",
      "F1 score: 0.9422575699805553\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      0.89      0.94      9000\n",
      "           1       0.90      1.00      0.95      9000\n",
      "\n",
      "    accuracy                           0.94     18000\n",
      "   macro avg       0.95      0.94      0.94     18000\n",
      "weighted avg       0.95      0.94      0.94     18000\n",
      "\n",
      "Model saved as: Logistic Regression_model.joblib\n",
      "\n",
      "\n",
      "Random Forest:\n",
      "Accuracy: 0.9996111111111111\n",
      "F1 score: 0.9996111110811042\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       1.00      1.00      1.00      9000\n",
      "           1       1.00      1.00      1.00      9000\n",
      "\n",
      "    accuracy                           1.00     18000\n",
      "   macro avg       1.00      1.00      1.00     18000\n",
      "weighted avg       1.00      1.00      1.00     18000\n",
      "\n",
      "Model saved as: Random Forest_model.joblib\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import SVC\n",
    "from joblib import dump\n",
    "\n",
    "# Create an empty DataFrame with the desired columns\n",
    "model_comparison = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"F1 Score\"])\n",
    "saved_models = {}  # Dictionary to store saved models\n",
    "\n",
    "\n",
    "# Train and evaluate machine learning models\n",
    "models = {\n",
    "    \"Logistic Regression\": LogisticRegression(max_iter=1000),\n",
    "    \"Random Forest\": RandomForestClassifier(),\n",
    "    \"Support Vector Machine\": SVC()\n",
    "}\n",
    "print(\"X shape\",X_train.shape)\n",
    "for name, model in models.items():\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Append the metrics to the DataFrame\n",
    "    model_comparison = model_comparison._append({\"Model\": name, \"Accuracy\": accuracy, \"F1 Score\": f1}, ignore_index=True)\n",
    "\n",
    "    # Save the trained model weight\n",
    "    filename = f\"{name}_model.joblib\"\n",
    "    dump(model, filename)\n",
    "    saved_models[name] = filename  # Store the filename for later use in the tested DataSets\n",
    "\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 score: {f1}\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(f\"Model saved as: {filename}\")\n",
    "    print(\"\\n\")\n",
    "\n",
    "display(model_comparison)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RZt2ZB1ruj09"
   },
   "outputs": [],
   "source": [
    "# # Get the Random Forest model from the 'models' dictionary\n",
    "# random_forest_model = models['Random Forest']\n",
    "\n",
    "# # Get feature importances\n",
    "# importances = random_forest_model.feature_importances_\n",
    "\n",
    "# # Create a DataFrame with the feature names and their corresponding importances\n",
    "# feature_importances = pd.DataFrame({'Feature': feature_columns, 'Importance': importances})\n",
    "\n",
    "# # Sort the DataFrame by importance in descending order\n",
    "# feature_importances = feature_importances.sort_values(by='Importance', ascending=False)\n",
    "\n",
    "# # Display the feature importances DataFrame\n",
    "# # Filter the DataFrame to show only features with non-zero importance\n",
    "# non_zero_importances = feature_importances[feature_importances['Importance'] > 0]\n",
    "\n",
    "# # Display the filtered DataFrame\n",
    "# non_zero_importances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hc_jAHTfuqMV"
   },
   "outputs": [],
   "source": [
    "# import seaborn as sns\n",
    "# import matplotlib.pyplot as plt\n",
    "# from sklearn.metrics import confusion_matrix\n",
    "\n",
    "\n",
    "# # Choose the model you want to use, for example, Random Forest\n",
    "# model = models[\"Random Forest\"]\n",
    "# y_pred = model.predict(X_test)\n",
    "\n",
    "\n",
    "# # Calculate the confusion matrix\n",
    "# cm = confusion_matrix(y_test, y_pred)\n",
    "\n",
    "\n",
    "# # Plot the confusion matrix using seaborn's heatmap\n",
    "# plt.figure(figsize=(5, 3))\n",
    "# sns.heatmap(cm, annot=True, fmt=\".2f\", cmap=\"Blues\", xticklabels=[\"0\", \"1\"], yticklabels=[\"0\", \"1\"])\n",
    "# plt.ylabel(\"True label\")\n",
    "# plt.xlabel(\"Predicted label\")\n",
    "# plt.title(\"Confusion Matrix - Random Forest\")\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Wtvq0IxFsRSJ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the DataFrame to store model comparison\n",
    "model_comparison = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"F1 Score\"])\n",
    "\n",
    "# Initialize dictionary to store confusion matrices\n",
    "confusion_matrices = {}\n",
    "\n",
    "# Initialize lists to store accuracy and F1 score for each model\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_test)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_test, y_pred)\n",
    "    f1 = f1_score(y_test, y_pred, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_pred)\n",
    "    confusion_matrices[name] = cm\n",
    "\n",
    "    # Append results to model comparison DataFrame\n",
    "    model_comparison = model_comparison._append({\"Model\": name, \"Accuracy\": accuracy, \"F1 Score\": f1}, ignore_index=True)\n",
    "\n",
    "    # Append accuracy and F1 score to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print model evaluation metrics and confusion matrix\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 score: {f1}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_test, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Plotting accuracy scores\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(model_comparison['Model'], accuracy_scores, color='skyblue')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting F1 scores\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(model_comparison['Model'], f1_scores, color='orange')\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Displaying the model comparison DataFrame\n",
    "print(\"Model Comparison:\")\n",
    "print(model_comparison)\n",
    "\n",
    "# Plot confusion matrices for each model using Seaborn\n",
    "for name, cm in confusion_matrices.items():\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\n",
    "    plt.title(f\"Confusion Matrix for {name}\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gZP--5ZNSlLw",
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "# Loading Saved model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5FryA8a9igzO"
   },
   "outputs": [],
   "source": [
    "#Load the saved model\n",
    "from joblib import load\n",
    "\n",
    "# Load each model individually\n",
    "# Give path of each model here\n",
    "logistic_regression_model = load(\"Logistic Regression_model.joblib\")\n",
    "random_forest_model = load(\"Random Forest_model.joblib\")\n",
    "svm_model = load(\"Support Vector Machine_model.joblib\")\n",
    "\n",
    "# Store the loaded models in a dictionary\n",
    "loaded_models = {\n",
    "    \"Logistic Regression\": logistic_regression_model,\n",
    "    \"Random Forest\": random_forest_model,\n",
    "    \"Support Vector Machine\": svm_model\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZrKkHH-11HZK",
    "outputId": "e2c7bf3f-f6e1-48e3-c265-5cfb61d6a11f"
   },
   "outputs": [],
   "source": [
    "loaded_models.items()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 211
    },
    "id": "yn6NKiPgkjol",
    "outputId": "13dd7107-e312-4cef-c1a1-d07a92335b58"
   },
   "outputs": [],
   "source": [
    "# Load the encoders\n",
    "with open('encoder_src_ip.pkl', 'rb') as f:\n",
    "    loaded_encoder_src_ip = pickle.load(f)\n",
    "\n",
    "with open('encoder_dst_ip.pkl', 'rb') as f:\n",
    "    loaded_encoder_dst_ip = pickle.load(f)\n",
    "\n",
    "with open('encoder_label.pkl', 'rb') as f:\n",
    "    loaded_encoder_label = pickle.load(f)\n",
    "\n",
    "print(\"Encoders loaded successfully!\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRRkOik01yfg"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nitxogSZ1yzg"
   },
   "source": [
    "##Preprocessing For Testing DATA Change Title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 159
    },
    "id": "tGNzsOc3ujsD",
    "outputId": "0b7bcfd3-0bfe-4f48-d9da-0fa1c89861e0"
   },
   "outputs": [],
   "source": [
    "\n",
    "feature_columns = X_train.columns\n",
    "feature_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "5b40kBNvA2eS"
   },
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d3Sj2hcC16Za"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ENgTyePU2MDI"
   },
   "outputs": [],
   "source": [
    "column_mapping = {'Flow ID': 'Flow ID',\n",
    " 'Src IP': ' Source IP',\n",
    " 'Src Port': ' Source Port',\n",
    " 'Dst IP': ' Destination IP',\n",
    " 'Dst Port': ' Destination Port',\n",
    " 'Protocol': ' Protocol',\n",
    " 'Timestamp': ' Timestamp',\n",
    " 'Flow Duration': ' Flow Duration',\n",
    " 'Tot Fwd Pkts': ' Total Fwd Packets',\n",
    " 'Tot Bwd Pkts': ' Total Backward Packets',\n",
    " 'TotLen Fwd Pkts': 'Total Length of Fwd Packets',\n",
    " 'TotLen Bwd Pkts': ' Total Length of Bwd Packets',\n",
    " 'Fwd Pkt Len Max': ' Fwd Packet Length Max',\n",
    " 'Fwd Pkt Len Min': ' Fwd Packet Length Min',\n",
    " 'Fwd Pkt Len Mean': ' Fwd Packet Length Mean',\n",
    " 'Fwd Pkt Len Std': ' Fwd Packet Length Std',\n",
    " 'Bwd Pkt Len Max': 'Bwd Packet Length Max',\n",
    " 'Bwd Pkt Len Min': ' Bwd Packet Length Min',\n",
    " 'Bwd Pkt Len Mean': ' Bwd Packet Length Mean',\n",
    " 'Bwd Pkt Len Std': ' Bwd Packet Length Std',\n",
    " 'Flow Byts/s': 'Flow Bytes/s',\n",
    " 'Flow Pkts/s': ' Flow Packets/s',\n",
    " 'Flow IAT Mean': ' Flow IAT Mean',\n",
    " 'Flow IAT Std': ' Flow IAT Std',\n",
    " 'Flow IAT Max': ' Flow IAT Max',\n",
    " 'Flow IAT Min': ' Flow IAT Min',\n",
    " 'Fwd IAT Tot': 'Fwd IAT Total',\n",
    " 'Fwd IAT Mean': ' Fwd IAT Mean',\n",
    " 'Fwd IAT Std': ' Fwd IAT Std',\n",
    " 'Fwd IAT Max': ' Fwd IAT Max',\n",
    " 'Fwd IAT Min': ' Fwd IAT Min',\n",
    " 'Bwd IAT Tot': 'Bwd IAT Total',\n",
    " 'Bwd IAT Mean': ' Bwd IAT Mean',\n",
    " 'Bwd IAT Std': ' Bwd IAT Std',\n",
    " 'Bwd IAT Max': ' Bwd IAT Max',\n",
    " 'Bwd IAT Min': ' Bwd IAT Min',\n",
    " 'Fwd PSH Flags': 'Fwd PSH Flags',\n",
    " 'Bwd PSH Flags': ' Bwd PSH Flags',\n",
    " 'Fwd URG Flags': ' Fwd URG Flags',\n",
    " 'Bwd URG Flags': ' Bwd URG Flags',\n",
    " 'Fwd Header Len': ' Fwd Header Length',\n",
    " 'Bwd Header Len': ' Bwd Header Length',\n",
    " 'Fwd Pkts/s': 'Fwd Packets/s',\n",
    " 'Bwd Pkts/s': ' Bwd Packets/s',\n",
    " 'Pkt Len Min': ' Min Packet Length',\n",
    " 'Pkt Len Max': ' Max Packet Length',\n",
    " 'Pkt Len Mean': ' Packet Length Mean',\n",
    " 'Pkt Len Std': ' Packet Length Std',\n",
    " 'Pkt Len Var': ' Packet Length Variance',\n",
    " 'FIN Flag Cnt': 'FIN Flag Count',\n",
    " 'SYN Flag Cnt': ' SYN Flag Count',\n",
    " 'RST Flag Cnt': ' RST Flag Count',\n",
    " 'PSH Flag Cnt': ' PSH Flag Count',\n",
    " 'ACK Flag Cnt': ' ACK Flag Count',\n",
    " 'URG Flag Cnt': ' URG Flag Count',\n",
    " 'CWE Flag Count': ' CWE Flag Count',\n",
    " 'ECE Flag Cnt': ' ECE Flag Count',\n",
    " 'Down/Up Ratio': ' Down/Up Ratio',\n",
    " 'Pkt Size Avg': ' Average Packet Size',\n",
    " 'Fwd Seg Size Avg': ' Avg Fwd Segment Size',\n",
    " 'Bwd Seg Size Avg': ' Avg Bwd Segment Size',\n",
    " 'Fwd Byts/b Avg': 'Fwd Avg Bytes/Bulk',\n",
    " 'Fwd Pkts/b Avg': ' Fwd Avg Packets/Bulk',\n",
    " 'Fwd Blk Rate Avg': ' Fwd Avg Bulk Rate',\n",
    " 'Bwd Byts/b Avg': ' Bwd Avg Bytes/Bulk',\n",
    " 'Bwd Pkts/b Avg': ' Bwd Avg Packets/Bulk',\n",
    " 'Bwd Blk Rate Avg': 'Bwd Avg Bulk Rate',\n",
    " 'Subflow Fwd Pkts': 'Subflow Fwd Packets',\n",
    " 'Subflow Fwd Byts': ' Subflow Fwd Bytes',\n",
    " 'Subflow Bwd Pkts': ' Subflow Bwd Packets',\n",
    " 'Subflow Bwd Byts': ' Subflow Bwd Bytes',\n",
    " 'Init Fwd Win Byts': 'Init_Win_bytes_forward',\n",
    " 'Init Bwd Win Byts': ' Init_Win_bytes_backward',\n",
    " 'Fwd Act Data Pkts': ' act_data_pkt_fwd',\n",
    " 'Fwd Seg Size Min': ' min_seg_size_forward',\n",
    " 'Active Mean': 'Active Mean',\n",
    " 'Active Std': ' Active Std',\n",
    " 'Active Max': ' Active Max',\n",
    " 'Active Min': ' Active Min',\n",
    " 'Idle Mean': 'Idle Mean',\n",
    " 'Idle Std': ' Idle Std',\n",
    " 'Idle Max': ' Idle Max',\n",
    " 'Idle Min': ' Idle Min',\n",
    " 'Label': 'Label'}\n",
    "\n",
    " # Function to standardize column names\n",
    "def standardize_columns(df, column_mapping):\n",
    "    # df = df.rename(columns=column_mapping)\n",
    "    if ' Label' in df.columns:\n",
    "        df = df.rename(columns={' Label': 'Label'})\n",
    "    return df\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "S-qMOEq4Ed-J"
   },
   "outputs": [],
   "source": [
    "# specific_columns = [' Source IP', ' Source Port',' Destination IP', ' Destination Port', ' Protocol',\n",
    "#        ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
    "#        'Total Length of Fwd Packets', ' Total Length of Bwd Packets','Label']\n",
    "\n",
    "specific_columns = [' Source IP', ' Source Port',' Destination IP', ' Destination Port',\n",
    "       ' Flow Duration', ' Total Fwd Packets', ' Total Backward Packets',\n",
    "       'Total Length of Fwd Packets', ' Total Length of Bwd Packets','Label']\n",
    "\n",
    "# Standardize column names\n",
    "rename_dict = {\n",
    "    ' Source IP': 'src_ip', ' Source Port': 'src_port', ' Destination IP': 'dst_ip', ' Destination Port': 'dst_port',\n",
    "    ' Protocol': 'protocol', ' Flow Duration': 'flow_duration', ' Total Fwd Packets': 'total_fwd_packets',\n",
    "    ' Total Backward Packets': 'total_bwd_packets', 'Total Length of Fwd Packets': 'total_len_fwd_packets',\n",
    "    ' Total Length of Bwd Packets': 'total_len_bwd_packets', ' Label': 'label',\n",
    "\n",
    "    'srcip': 'src_ip', 'sport': 'src_port', 'dstip': 'dst_ip', 'dsport': 'dst_port',\n",
    "    'proto': 'protocol', 'dur': 'flow_duration', 'Spkts': 'total_fwd_packets', 'Dpkts': 'total_bwd_packets',\n",
    "    'sbytes': 'total_len_fwd_packets', 'dbytes': 'total_len_bwd_packets', 'Label': 'label'\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "GWlWTIvr2rbr"
   },
   "outputs": [],
   "source": [
    "# column_mapping == column_mapping1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-D7xkdrRRujD",
    "tags": []
   },
   "source": [
    "# Loading target dataset to test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "w8rGrRtwi0uM",
    "outputId": "9ccf315b-1cd0-46ee-f5c3-c3d4ec5e850f"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the new dataset we going to test the model on:\n",
    "url = \"https://ddosciu.s3.us-east-2.amazonaws.com/PCAPs/Test.csv\"\n",
    "#Test1\n",
    "url1 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/HTTP_Ddos.pcap_Flow.csv\"\n",
    "url2 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/amp.TCP.syn.optionallyACK.optionallysamePort.pcapng_Flow.csv\"\n",
    "url3 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/amp.TCP.reflection.SYNACK.pcap_Flow.csv\"\n",
    "url4 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/amp.UDP.bacnet.IOT.37810.pcapng_Flow.csv\"\n",
    "url5 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/1.pcap_Flow.csv\"\n",
    "url6 =\"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/amp.dns.RRSIG.fragmented.pcap_Flow.csv\"\n",
    "url7 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/amp.UDP.isakmp.pcap_Flow.csv\"\n",
    "url8 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/pkt.ICMP.largeempty.pcap_Flow.csv\"\n",
    "url9 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/pkt.TCP.DOMINATE.syn.ecn.cwr.pcapng_Flow.csv\"\n",
    "url10 = \"/content/NormalTraffic2.pcap_Flow.csv\"\n",
    "url11= \"https://ddosciu.s3.us-east-2.amazonaws.com/IC_Taraf.root.1.pcap_Flow.csv\"\n",
    "url12 = \"/content/drive/MyDrive/online_tasks/Portmap.csv\"\n",
    "url13 = \"https://ddosciu.s3.us-east-2.amazonaws.com/CSV's/Train.csv\"\n",
    "url14 = \"/content/drive/MyDrive/online_tasks/UNSW-NB15_4.csv\"\n",
    "url15 = \"/content/drive/MyDrive/online_tasks/Friday-WorkingHours-Afternoon-DDos.pcap_ISCX.csv\"\n",
    "url16 = \"https://ddosciu.s3.us-east-2.amazonaws.com/LDAP.csv\"\n",
    "new_data = pd.read_csv(url16)\n",
    "\n",
    "# Apply the column mapping to the testing data\n",
    "new_data = standardize_columns(new_data, column_mapping)\n",
    "\n",
    "new_data = new_data.rename(columns=column_mapping)\n",
    "# new_data = data_2.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 141
    },
    "id": "T6TR_h2Zp-4I",
    "outputId": "583cb591-6453-46b5-af85-bdec3d8e1e57"
   },
   "outputs": [],
   "source": [
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cW1WNCBjE8zh",
    "outputId": "2aaa28b2-ea4d-4f70-b5d9-93162ecee649"
   },
   "outputs": [],
   "source": [
    "new_data = new_data[specific_columns]\n",
    "\n",
    "new_data.rename(columns=rename_dict, inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "iqceS9yXcfUA",
    "outputId": "ec870eb7-3db3-481e-b4ec-108e46e0eb7e"
   },
   "outputs": [],
   "source": [
    "new_data.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ov3Qy0oQcUuv"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "osEj0ittA4Ts",
    "outputId": "24468477-e723-4490-dfb7-395581c50394"
   },
   "outputs": [],
   "source": [
    "len(X.columns),len(new_data.columns)\n",
    "# Check for missing columns in new_data compared to train data X\n",
    "missing_columns = set(X.columns) - set(new_data.columns)\n",
    "\n",
    "# Check for missing columns in train data X compared to new_data\n",
    "extra_columns = set(new_data.columns) - set(X.columns)\n",
    "\n",
    "print(\"Columns missing in new_data:\", missing_columns)\n",
    "print(\"Columns extra in new_data:\", extra_columns)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "kRgQReS8QGkK"
   },
   "outputs": [],
   "source": [
    "# new_data['label'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "C6Hmz79GADRW"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 226
    },
    "id": "6S-vpcNyCqcl",
    "outputId": "5abb58ff-afa3-4a73-db94-427fbae2b5f4"
   },
   "outputs": [],
   "source": [
    "new_data.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jaMqYH8C_XAh"
   },
   "outputs": [],
   "source": [
    "# Transform the test data using the loaded encoders\n",
    "# new_data['src_ip'] = loaded_encoder_src_ip.transform(new_data['src_ip'])\n",
    "# new_data['dst_ip'] = loaded_encoder_dst_ip.transform(new_data['dst_ip'])\n",
    "# new_data['label'] = loaded_encoder_label.transform(new_data['label'])\n",
    "\n",
    "\n",
    "# # Encode categorical features (e.g., IP addresses)\n",
    "# encoder = LabelEncoder()\n",
    "# new_data['src_ip'] = encoder.fit_transform(new_data['src_ip'])\n",
    "# new_data['dst_ip'] = encoder.fit_transform(new_data['dst_ip'])\n",
    "# # new_data['protocol'] = encoder.fit_transform(new_data['protocol'])\n",
    "# new_data['label'] = encoder.fit_transform(new_data['label'])\n",
    "# new_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 747
    },
    "id": "nFH_Hg9zmDY3",
    "outputId": "020b9cc6-042b-4a57-8665-70b6ed8db052"
   },
   "outputs": [],
   "source": [
    "# Create separate LabelEncoders for each categorical feature\n",
    "encoder_src_ip = LabelEncoder()\n",
    "encoder_dst_ip = LabelEncoder()\n",
    "encoder_src_port = LabelEncoder()\n",
    "encoder_dst_port = LabelEncoder()\n",
    "\n",
    "encoder_label = LabelEncoder()\n",
    "\n",
    "# Fit and transform the categorical features\n",
    "new_data['src_ip'] = encoder_src_ip.fit_transform(new_data['src_ip'])\n",
    "new_data['dst_ip'] = encoder_dst_ip.fit_transform(new_data['dst_ip'])\n",
    "new_data['src_port'] = encoder_src_port.fit_transform(new_data['src_port'])\n",
    "new_data['dst_port'] = encoder_dst_port.fit_transform(new_data['dst_port'].astype(str))\n",
    "\n",
    "new_data['label'] = encoder_label.fit_transform(new_data['label'])\n",
    "new_data.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "7xpQU2yfiNcb",
    "outputId": "2d3f5dba-66cc-46dd-e50f-b6b8da6837be"
   },
   "outputs": [],
   "source": [
    "set(new_data['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "GAUlYXvvtw9O",
    "outputId": "c3ee8de5-822f-45ca-9088-5bacabb79181"
   },
   "outputs": [],
   "source": [
    "# Inspect the mapping between original labels and encoded numbers\n",
    "print(\"Mapping between original labels and encoded numbers:\")\n",
    "for label, encoded_label in zip(encoder_label.classes_, encoder_label.transform(encoder_label.classes_)):\n",
    "    print(f\"{label}: {encoded_label}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Hsdj1VWT_gtK"
   },
   "outputs": [],
   "source": [
    "X_new = new_data.drop('label', axis=1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3w3vyogQb8iE"
   },
   "outputs": [],
   "source": [
    "X_new.replace([np.inf, -np.inf], np.nan, inplace=True)\n",
    "imputer = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_new = imputer.fit_transform(X_new)\n",
    "scaler = StandardScaler()\n",
    "X_new = scaler.fit_transform(X_new)\n",
    "\n",
    "#Labels for comparison (They are not always available for some datasets)\n",
    "y_new = new_data['label']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hc83C6eK_XjD",
    "outputId": "f87b8a18-261a-41ce-ad41-a331c9b262dc"
   },
   "outputs": [],
   "source": [
    "y_new.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yz2fc-oDBfw_"
   },
   "source": [
    "### Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JXtxYcPwmnnR",
    "outputId": "3e9fb9f9-b807-44ba-f4d2-3a500fb2da16"
   },
   "outputs": [],
   "source": [
    "# Now, i can use the loaded models to make predictions on the preprocessed new dataset\n",
    "predictions = {}\n",
    "for name, model in loaded_models.items():\n",
    "    predictions[name] = model.predict(X_new)\n",
    "\n",
    "# Print predictions for each model\n",
    "for name, preds in predictions.items():\n",
    "    print(f\"Predictions using {name}: {preds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jcW6mhPs7cb1",
    "outputId": "4d49b067-7992-4d33-fe04-161dc9a34fbb"
   },
   "outputs": [],
   "source": [
    "# Define a mapping from encoded labels to original labels\n",
    "label_mapping = {0: 'BENIGN', 1: 'LDAP', 2: 'NetBIOS'}\n",
    "\n",
    "# Now, you can use the loaded models to make predictions on the preprocessed new dataset\n",
    "predictions = {}\n",
    "\n",
    "# Iterate through each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions using the current model\n",
    "    preds = model.predict(X_new)\n",
    "    # Map encoded predictions to their original labels\n",
    "    mapped_preds = [label_mapping[pred] for pred in preds]\n",
    "    # Store the mapped predictions\n",
    "    predictions[name] = mapped_preds\n",
    "\n",
    "# Print mapped predictions for each model\n",
    "for name, preds in predictions.items():\n",
    "    print(f\"Predictions using {name}: {preds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "Q_VVt80c9hIN",
    "outputId": "8e2cf72a-51c1-4f56-972b-d1fb34c6c914"
   },
   "outputs": [],
   "source": [
    "# Initialize an empty DataFrame\n",
    "all_predictions_df = pd.DataFrame()\n",
    "\n",
    "# Initialize a list to store model names\n",
    "model_names = []\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_new)\n",
    "\n",
    "    # Map the predicted labels\n",
    "    mapped_predictions = [label_mapping[label] for label in y_pred]\n",
    "\n",
    "    # Add the model name to the list\n",
    "    model_names.append(name)\n",
    "\n",
    "    # Create a DataFrame for predicted labels\n",
    "    predicted_labels_df = pd.DataFrame({'Predicted_Label': y_pred, 'Mapped_Prediction': mapped_predictions})\n",
    "\n",
    "    # Add the DataFrame to the overall DataFrame\n",
    "    all_predictions_df = pd.concat([all_predictions_df, predicted_labels_df], axis=1)\n",
    "\n",
    "# Set the column names for the first row\n",
    "all_predictions_df.columns = pd.MultiIndex.from_product([model_names, ['Predicted_Label', 'Mapped_Prediction']])\n",
    "\n",
    "# Print the DataFrame\n",
    "all_predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "eG2zx34aBmDG",
    "outputId": "6026e667-9c1f-4a3f-e1f9-b881938ef959"
   },
   "outputs": [],
   "source": [
    "# Define a mapping from encoded labels to original labels\n",
    "label_mapping = {0: 'No Attack'}\n",
    "\n",
    "# Now, you can use the loaded models to make predictions on the preprocessed new dataset\n",
    "predictions = {}\n",
    "\n",
    "# Iterate through each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions using the current model\n",
    "    preds = model.predict(X_new)\n",
    "    # Map encoded predictions to their original labels\n",
    "    mapped_preds = ['No Attack' if pred == 0 else 'DDos Attack' for pred in preds]\n",
    "    # Store the mapped predictions\n",
    "    predictions[name] = mapped_preds\n",
    "\n",
    "# Print mapped predictions for each model\n",
    "for name, preds in predictions.items():\n",
    "    print(f\"Predictions using {name}: {preds}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "FPoaPmgb1n68",
    "outputId": "f063be74-3bff-4cdd-d323-ba023ad017fc"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score, confusion_matrix\n",
    "\n",
    "# Define a mapping from encoded labels to original labels\n",
    "label_mapping = {0: 'No Attack', 1: 'DDoS Attack'}\n",
    "\n",
    "# Placeholder for predictions, accuracies, and confusion matrices\n",
    "predictions = {}\n",
    "accuracies = {}\n",
    "confusion_matrices = {}\n",
    "\n",
    "# Iterate through each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions using the current model\n",
    "    preds = model.predict(X_new)\n",
    "\n",
    "    # Store the predictions\n",
    "    predictions[name] = preds\n",
    "\n",
    "    # Calculate accuracy using numeric labels\n",
    "    accuracy = accuracy_score(y_new, preds)\n",
    "    accuracies[name] = accuracy\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_new, preds)\n",
    "    confusion_matrices[name] = cm\n",
    "\n",
    "    # Map encoded predictions to their original labels for display\n",
    "    mapped_preds = [label_mapping[pred] for pred in preds]\n",
    "\n",
    "    # Print mapped predictions for each model\n",
    "    print(f\"Predictions using {name}: {mapped_preds[:10]}...\")  # Print only the first 10 for brevity\n",
    "    print(f\"Accuracy for {name}: {accuracy:.4f}\")\n",
    "    print(f\"Confusion Matrix for {name}:\\n{cm}\\n\")\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for each model:\")\n",
    "for name, accuracy in accuracies.items():\n",
    "    print(f\"{name}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "_lvS_9wJ2tj0",
    "outputId": "e51dc537-9970-4d42-b58f-ae9ad7163cf9"
   },
   "outputs": [],
   "source": [
    "# Check class distribution in the training data\n",
    "print(\"Class distribution in y_train:\")\n",
    "print(pd.Series(y_train).value_counts())\n",
    "\n",
    "# Check class distribution in the test data\n",
    "print(\"Class distribution in y_new:\")\n",
    "print(pd.Series(y_new).value_counts())\n",
    "\n",
    "# Make predictions and calculate accuracy and confusion matrix for each model\n",
    "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
    "\n",
    "# Define a mapping from encoded labels to original labels\n",
    "label_mapping = {0: 'No Attack', 1: 'DDoS Attack'}\n",
    "\n",
    "# Placeholder for predictions, accuracies, and confusion matrices\n",
    "predictions = {}\n",
    "accuracies = {}\n",
    "confusion_matrices = {}\n",
    "\n",
    "# Iterate through each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions using the current model\n",
    "    preds = model.predict(X_new)\n",
    "\n",
    "    # Store the predictions\n",
    "    predictions[name] = preds\n",
    "\n",
    "    # Calculate accuracy using numeric labels\n",
    "    accuracy = accuracy_score(y_new, preds)\n",
    "    accuracies[name] = accuracy\n",
    "\n",
    "    # Generate confusion matrix\n",
    "    cm = confusion_matrix(y_new, preds)\n",
    "    confusion_matrices[name] = cm\n",
    "\n",
    "    # Map encoded predictions to their original labels for display\n",
    "    mapped_preds = [label_mapping[pred] for pred in preds]\n",
    "\n",
    "    # Print mapped predictions for each model\n",
    "    print(f\"Predictions using {name}: {mapped_preds[:10]}...\")  # Print only the first 10 for brevity\n",
    "    print(f\"Accuracy for {name}: {accuracy:.4f}\")\n",
    "    print(f\"Confusion Matrix for {name}:\\n{cm}\\n\")\n",
    "    print(f\"Classification Report for {name}:\\n{classification_report(y_new, preds, target_names=list(label_mapping.values()))}\\n\")\n",
    "\n",
    "# Print all accuracies\n",
    "print(\"\\nAccuracies for each model:\")\n",
    "for name, accuracy in accuracies.items():\n",
    "    print(f\"{name}: {accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 579
    },
    "id": "NKhmYD31BpEO",
    "outputId": "ca4eb41a-2ed2-4c91-8dda-b2d286e8a54b"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "all_predictions_df = pd.DataFrame()\n",
    "\n",
    "# Initialize a list to store model names\n",
    "model_names = []\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_new)\n",
    "\n",
    "    # Map the predicted labels\n",
    "    mapped_predictions = ['No Attack' if label == 0 else 'Attack' for label in y_pred]\n",
    "\n",
    "    # Add the model name to the list\n",
    "    model_names.append(name)\n",
    "\n",
    "    # Create a DataFrame for predicted labels\n",
    "    predicted_labels_df = pd.DataFrame({'Predicted_Label': y_pred, 'Mapped_Prediction': mapped_predictions})\n",
    "\n",
    "    # Add the DataFrame to the overall DataFrame\n",
    "    all_predictions_df = pd.concat([all_predictions_df, predicted_labels_df], axis=1)\n",
    "\n",
    "# Set the column names for the first row\n",
    "all_predictions_df.columns = pd.MultiIndex.from_product([model_names, ['Predicted_Label', 'Mapped_Prediction']])\n",
    "\n",
    "# Print the DataFrame\n",
    "all_predictions_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vlj-IcPcHC7q"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BCUmsOnPHIkf"
   },
   "outputs": [],
   "source": [
    "#Savinf model prediction to CSV file\n",
    "all_predictions_df.to_csv('test_predictions.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SuYSrD_DranY",
    "outputId": "b31af589-4dd8-4d52-e128-c6c494e7e4a0"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming X_new and y_new are already defined\n",
    "# Example:\n",
    "# X_new = ...\n",
    "# y_new = ...\n",
    "\n",
    "# Initialize an empty DataFrame for predictions\n",
    "all_predictions_df = pd.DataFrame()\n",
    "\n",
    "# Initialize a list to store model names and accuracies\n",
    "model_names = []\n",
    "accuracies = []\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_new)\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = accuracy_score(y_new, y_pred)\n",
    "    accuracies.append(accuracy)\n",
    "\n",
    "    # Map the predicted labels\n",
    "    mapped_predictions = ['No Attack' if label == 0 else 'Attack' for label in y_pred]\n",
    "\n",
    "    # Add the model name to the list\n",
    "    model_names.append(name)\n",
    "\n",
    "    # Create a DataFrame for predicted labels\n",
    "    predicted_labels_df = pd.DataFrame({'Predicted_Label': y_pred, 'Mapped_Prediction': mapped_predictions})\n",
    "\n",
    "    # Add the DataFrame to the overall DataFrame\n",
    "    all_predictions_df = pd.concat([all_predictions_df, predicted_labels_df], axis=1)\n",
    "\n",
    "# Set the column names for the first row\n",
    "all_predictions_df.columns = pd.MultiIndex.from_product([model_names, ['Predicted_Label', 'Mapped_Prediction']])\n",
    "\n",
    "# Create a DataFrame for accuracies\n",
    "accuracy_df = pd.DataFrame({'Model': model_names, 'Accuracy': accuracies})\n",
    "\n",
    "# Print the predictions DataFrame\n",
    "print(all_predictions_df)\n",
    "\n",
    "# Print the accuracies DataFrame\n",
    "print(accuracy_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8QQ1c7dXhiLj",
    "outputId": "33ff9f8f-a90c-4057-dacc-60a2fab9c147"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xTC0YRQQogkO"
   },
   "outputs": [],
   "source": [
    "# #Manual label part\n",
    "# import pandas as pd\n",
    "\n",
    "# # Initialize an empty DataFrame\n",
    "# all_predictions_df = pd.DataFrame()\n",
    "\n",
    "# # Initialize a list to store model names\n",
    "# model_names = []\n",
    "\n",
    "# # Assign manual labels (all zeros) based on the length of X_new\n",
    "# manual_labels = [1,2] * len(X_new)\n",
    "\n",
    "# # Iterate over each loaded model\n",
    "# for name, model in loaded_models.items():\n",
    "#     # Make predictions on test data\n",
    "#     y_pred = model.predict(X_new)\n",
    "\n",
    "#     # Map the predicted labels\n",
    "#     mapped_predictions = ['No Attack' if label == 0 else 'Attack' for label in y_pred]\n",
    "\n",
    "#     # Calculate accuracy\n",
    "#     accuracy = sum(1 for pred, true in zip(y_pred, manual_labels) if pred == true) / len(manual_labels)\n",
    "\n",
    "#     # Print accuracy for each model\n",
    "#     print(f\"Accuracy for {name}: {accuracy}\")\n",
    "\n",
    "#     # Add the model name to the list\n",
    "#     model_names.append(name)\n",
    "\n",
    "#     # Create a DataFrame for predicted labels\n",
    "#     predicted_labels_df = pd.DataFrame({'Predicted_Label': y_pred, 'Mapped_Prediction': mapped_predictions})\n",
    "\n",
    "#     # Add the DataFrame to the overall DataFrame\n",
    "#     all_predictions_df = pd.concat([all_predictions_df, predicted_labels_df], axis=1)\n",
    "\n",
    "# # Set the column names for the first row\n",
    "# all_predictions_df.columns = pd.MultiIndex.from_product([model_names, ['Predicted_Label', 'Mapped_Prediction']])\n",
    "\n",
    "# # Print the DataFrame\n",
    "# print(all_predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "sHYD57H4rC8A"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3SsEwF3ORQ78",
    "outputId": "8580c96e-592d-4802-9dac-19160b98ba87"
   },
   "outputs": [],
   "source": [
    "#Manual label part\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize an empty DataFrame\n",
    "all_predictions_df = pd.DataFrame()\n",
    "\n",
    "# Initialize a list to store model names\n",
    "model_names = []\n",
    "\n",
    "# Assign manual labels (all zeros) based on the length of X_new\n",
    "manual_labels = y_new\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_new)\n",
    "\n",
    "    # Map the predicted labels\n",
    "    mapped_predictions = ['No Attack' if label == 0 else 'Attack' for label in y_pred]\n",
    "\n",
    "    # Calculate accuracy\n",
    "    accuracy = sum(1 for pred, true in zip(y_pred, manual_labels) if pred == true) / len(manual_labels)\n",
    "\n",
    "    # Print accuracy for each model\n",
    "    print(f\"Accuracy for {name}: {accuracy}\")\n",
    "\n",
    "    # Add the model name to the list\n",
    "    model_names.append(name)\n",
    "\n",
    "    # Create a DataFrame for predicted labels\n",
    "    predicted_labels_df = pd.DataFrame({'Predicted_Label': y_pred, 'Mapped_Prediction': mapped_predictions})\n",
    "\n",
    "    # Add the DataFrame to the overall DataFrame\n",
    "    all_predictions_df = pd.concat([all_predictions_df, predicted_labels_df], axis=1)\n",
    "\n",
    "# Set the column names for the first row\n",
    "all_predictions_df.columns = pd.MultiIndex.from_product([model_names, ['Predicted_Label', 'Mapped_Prediction']])\n",
    "\n",
    "# Print the DataFrame\n",
    "print(all_predictions_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "FQ5vngRkrYUk",
    "outputId": "3e0cfef4-5655-4da6-b657-93a76b91bf3c"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, confusion_matrix\n",
    "\n",
    "# Initialize the DataFrame to store model comparison\n",
    "model_comparison = pd.DataFrame(columns=[\"Model\", \"Accuracy\", \"F1 Score\"])\n",
    "\n",
    "# Initialize dictionary to store confusion matrices\n",
    "confusion_matrices = {}\n",
    "\n",
    "# Initialize lists to store accuracy and F1 score for each model\n",
    "accuracy_scores = []\n",
    "f1_scores = []\n",
    "\n",
    "# Iterate over each loaded model\n",
    "for name, model in loaded_models.items():\n",
    "    # Make predictions on test data\n",
    "    y_pred = model.predict(X_new)\n",
    "\n",
    "    # Calculate evaluation metrics\n",
    "    accuracy = accuracy_score(y_new, y_pred)\n",
    "    f1 = f1_score(y_new, y_pred, average='weighted')\n",
    "\n",
    "    # Calculate confusion matrix\n",
    "    cm = confusion_matrix(y_new, y_pred)\n",
    "    confusion_matrices[name] = cm\n",
    "\n",
    "    # Append results to model comparison DataFrame\n",
    "    model_comparison = model_comparison._append({\"Model\": name, \"Accuracy\": accuracy, \"F1 Score\": f1}, ignore_index=True)\n",
    "\n",
    "    # Append accuracy and F1 score to lists\n",
    "    accuracy_scores.append(accuracy)\n",
    "    f1_scores.append(f1)\n",
    "\n",
    "    # Print model evaluation metrics and confusion matrix\n",
    "    print(f\"{name}:\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"F1 score: {f1}\")\n",
    "    print(\"Classification Report:\")\n",
    "    print(classification_report(y_new, y_pred))\n",
    "    print(\"\\n\")\n",
    "\n",
    "# Plotting accuracy scores\n",
    "plt.figure(figsize=(8, 4))\n",
    "plt.bar(model_comparison['Model'], accuracy_scores, color='skyblue')\n",
    "plt.title('Accuracy Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Plotting F1 scores\n",
    "plt.figure(figsize=(6, 3))\n",
    "plt.bar(model_comparison['Model'], f1_scores, color='orange')\n",
    "plt.title('F1 Score Comparison')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('F1 Score')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()\n",
    "\n",
    "# Displaying the model comparison DataFrame\n",
    "print(\"Model Comparison:\")\n",
    "print(model_comparison)\n",
    "\n",
    "# Plot confusion matrices for each model using Seaborn\n",
    "for name, cm in confusion_matrices.items():\n",
    "    plt.figure(figsize=(6, 3))\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=True, yticklabels=True)\n",
    "    plt.title(f\"Confusion Matrix for {name}\")\n",
    "    plt.xlabel(\"Predicted Labels\")\n",
    "    plt.ylabel(\"True Labels\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "RxcP6YX1slCN"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
